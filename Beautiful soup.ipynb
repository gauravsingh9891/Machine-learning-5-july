{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "  import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get(\"https://www.crummy.com/software/BeautifulSoup/bs3/documentation.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "requests.models.Response"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\"\\n\"http://www.w3.org/TR/REC-html40/transitional.dtd\">\\n<html>\\n<head>\\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\\n<title>Beautiful Soup documentation</title>\\n<link rev=\"made\" href=\"mailto:leonardr@segfault.org\">\\n<link rel=\"stylesheet\" type=\"text/css\" href=\"/nb/themes/Default/nb.css\">\\n<meta name=\"generator\" content=\"Markov Approximation 1.4 (module: leonardr)\">\\n<meta name=\"author\" content=\"Leonard Richardson\">\\n</head>\\n<body bgcolor=\"white\" text=\"black\" link=\"blue\" vlink=\"660066\" alink=\"red\">\\n<style>\\n div.sample { border-style: solid; border-width: 1px; background:#FFFFFF}\\n samp { background:#EEFFEE}\\n</style>\\n\\n<img align=\"right\" src=\"6.1.jpg\" height=\"250\" width=\"209\">\\n\\n<h1>Beautiful Soup Documentation</h1>\\nby <a href=\"http://www.crummy.com/\">Leonard Richardson</a>\\n(leonardr&#64;segfault&#46;org)\\n\\n<p><A href=\"documentation.zh.html\">这份文档也有中文版了</a> (This document is\\nalso available in Chinese translation)\\n\\n<p><a href=\"http://wiki.python.su/%D0%94%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D0%B0%D1%86%D0%B8%D0%B8/BeautifulSoup\">Этот документ также доступен в русском переводе. [Внешняя ссылка]</a> (This document is\\nalso available in Russian translation. [External link])\\n\\n<div width=\"50%\" style=\"background-color:#ffcccc; border-style:solid; border-width=1px;\">\\n<p><b>Beautiful Soup 3 has been replaced\\n by <a\\n href=\"http://www.crummy.com/software/BeautifulSoup/bs4/\">Beautiful\\n Soup 4</a>.</b> You may be looking for the <a\\n href=\"http://www.crummy.com/software/BeautifulSoup/bs4/doc/\">Beautiful\\n Soup 4 documentation</a></p>\\n\\n <p>Beautiful Soup 3 only works on Python 2.x, but Beautiful Soup 4\\n also works on Python 3.x. Beautiful Soup 4 is faster, has more\\n features, and works with third-party parsers like lxml and\\n html5lib. You should use Beautiful Soup 4 for all new projects.</p>\\n</div>\\n\\n<p><div width=\"50%\" style=\"background-color:#ffcccc; border-style:solid; border-width=1px;\">\\n<p>Beautiful Soup 3 は <a\\nhref=\"http://www.crummy.com/software/BeautifulSoup/bs4/doc/\">Beautiful\\nSoup 4</a> に更新されました。 あなたが探しているのは、<a\\nhref=\"http://www.crummy.com/software/BeautifulSoup/bs4/doc/\">Beautiful\\nSoup 4 documentation</a> ではありませんか。<a\\nhref=\"http://kondou.com/BS4/\">Beautiful Soup 4 ドキュメント</a> は日本語\\nでも読むことができます。\\n\\n<p><a href=\"http://tdoc.info/beautifulsoup/\">このドキュメントでは、（外部リンク）日本語訳でもご覧になれます。</a>\\n</div>\\n\\n<p><div width=\"50%\" style=\"background-color:#ffcccc; border-style:solid; border-width=1px;\">\\nBeautiful Soup 3已经被Beautiful Soup 4替代.请在新的项目中查看<a href=\"http://www.crummy.com/software/BeautifulSoup/bs4/doc/index.zh.html\">Beautiful Soup 4</a>的文档.\\n\\n<p>Beautiful Soup 3只能在python2.x版本中运行,而Beautiful Soup 4还可以在python3.x版本中运行.Beautiful Soup 4速度更快,特性更多,而且与第三方的文档解析库(如lxml和html5lib)协同工作.推荐在新的项目中使用Beautiful Soup 4.</p>\\n\\n</div>\\n\\n\\n<hr />\\n\\n<p><a href=\"http://www.crummy.com/software/BeautifulSoup/\">Beautiful\\nSoup</a> is an HTML/XML parser for Python that can turn even invalid\\nmarkup into a parse tree. It provides simple, idiomatic ways of\\nnavigating, searching, and modifying the parse tree. It commonly saves\\nprogrammers hours or days of work. There\\'s also a Ruby port called <a\\nhref=\"http://www.crummy.com/software/RubyfulSoup/\">Rubyful Soup</a>.\\n\\n<p>This document illustrates all major features of Beautiful Soup\\nversion 3.0, with examples. It shows you what the library is good for,\\nhow it works, how to use it, how to make it do what you want, and what\\nto do when it violates your expectations.\\n\\n<h2>Table of Contents</h2>\\n\\n<ul>\\n<li><a href=\"#Quick Start\">Quick Start</a></li></li>\\n<li><a href=\"#Parsing a Document\">Parsing a Document</a></li></li>\\n<ul>\\n<li><a href=\"#Parsing HTML\">Parsing HTML</a></li></li>\\n<li><a href=\"#Parsing XML\">Parsing XML</a></li></li>\\n<li><a href=\"#If That Doesn\\'t Work\">If That Doesn\\'t Work</a></li></li>\\n</ul>\\n<li><a href=\"#Beautiful Soup Gives You Unicode, Dammit\">Beautiful Soup Gives You Unicode, Dammit</a></li></li>\\n<li><a href=\"#Printing a Document\">Printing a Document</a></li></li>\\n<li><a href=\"#The Parse Tree\">The Parse Tree</a></li></li>\\n<ul>\\n<li><a href=\"#The attributes of Tags\">The attributes of <code>Tag</code>s</a></li></li>\\n</ul>\\n<li><a href=\"#Navigating the Parse Tree\">Navigating the Parse Tree</a></li></li>\\n<ul>\\n<li><a href=\"#parent\"><code>parent</code></a></li></li>\\n<li><a href=\"#contents\"><code>contents</code></a></li></li>\\n<li><a href=\"#string\"><code>string</code></a></li></li>\\n<li><a href=\"#nextSibling and previousSibling\"><code>nextSibling</code> and <code>previousSibling</code></a></li></li>\\n<li><a href=\"#next and previous\"><code>next</code> and <code>previous</code></a></li></li>\\n<li><a href=\"#Iterating over a Tag\">Iterating over a <code>Tag</code></a></li></li>\\n<li><a href=\"#Using tag names as members\">Using tag names as members</a></li></li>\\n</ul>\\n<li><a href=\"#Searching the Parse Tree\">Searching the Parse Tree</a></li></li>\\n<ul>\\n<li><a href=\"#The basic find method: findAll(name, attrs, recursive, text, limit, **kwargs)\">The basic find method: <code>findAll(name, attrs, recursive, text, limit, **kwargs)</code></a></li></li>\\n<ul>\\n<li><a href=\"#Searching by CSS class\">Searching by CSS class</a></li></li>\\n<li><a href=\"#Calling a tag is like calling findall\">Calling a tag is like calling <code>findall</code></a></li></li>\\n</ul>\\n<li><a href=\"#find(name, attrs, recursive, text, **kwargs)\"><code>find(name, attrs, recursive, text, **kwargs)</code></a></li></li>\\n<li><a href=\"#What happened to first?\">What happened to <code>first</code>?</a></li></li>\\n</ul>\\n<li><a href=\"#Searching Within the Parse Tree\">Searching Within the Parse Tree</a></li></li>\\n<ul>\\n<li><a href=\"#findNextSiblings(name, attrs, text, limit, **kwargs) and findNextSibling(name, attrs, text, **kwargs)\"><code>findNextSiblings(name, attrs, text, limit, **kwargs)</code> and <code>findNextSibling(name, attrs, text, **kwargs)</code></a></li></li>\\n<li><a href=\"#findPreviousSiblings(name, attrs, text, limit, **kwargs) and findPreviousSibling(name, attrs, text, **kwargs)\"><code>findPreviousSiblings(name, attrs, text, limit, **kwargs)</code> and <code>findPreviousSibling(name, attrs, text, **kwargs)</code></a></li></li>\\n<li><a href=\"#findAllNext(name, attrs, text, limit, **kwargs) and findNext(name, attrs, text, **kwargs)\"><code>findAllNext(name, attrs, text, limit, **kwargs)</code> and <code>findNext(name, attrs, text, **kwargs)</code></a></li></li>\\n<li><a href=\"#findAllPrevious(name, attrs, text, limit, **kwargs) and findPrevious(name, attrs, text, **kwargs)\"><code>findAllPrevious(name, attrs, text, limit, **kwargs)</code> and <code>findPrevious(name, attrs, text, **kwargs)</code></a></li></li>\\n</ul>\\n<li><a href=\"#Modifying the Parse Tree\">Modifying the Parse Tree</a></li></li>\\n<ul>\\n<li><a href=\"#Changing attribute values\">Changing attribute values</a></li></li>\\n<li><a href=\"#Removing elements\">Removing elements</a></li></li>\\n<li><a href=\"#Replacing one Element with Another\">Replacing one Element with Another</a></li></li>\\n<li><a href=\"#Adding a Brand New Element\">Adding a Brand New Element</a></li></li>\\n</ul>\\n<li><a href=\"#Troubleshooting\">Troubleshooting</a></li></li>\\n<ul>\\n<li><a href=\"#Why can\\'t Beautiful Soup print out the non-ASCII characters I gave it?\">Why can\\'t Beautiful Soup print out the non-ASCII characters I gave it?</a></li></li>\\n<li><a href=\"#Beautiful Soup loses the data I fed it! Why? WHY?????\">Beautiful Soup loses the data I fed it! Why? WHY?????</a></li></li>\\n<li><a href=\"#Beautiful Soup is too slow!\">Beautiful Soup is too slow!</a></li></li>\\n</ul>\\n<li><a href=\"#Advanced Topics\">Advanced Topics</a></li></li>\\n<ul>\\n<li><a href=\"#Generators\">Generators</a></li></li>\\n<li><a href=\"#Other Built-In Parsers\">Other Built-In Parsers</a></li></li>\\n<li><a href=\"#Customizing the Parser\">Customizing the Parser</a></li></li>\\n<li><a href=\"#Entity Conversion\">Entity Conversion</a></li></li>\\n<li><a href=\"#Sanitizing Bad Data with Regexps\">Sanitizing Bad Data with Regexps</a></li></li>\\n<li><a href=\"#Fun With SoupStrainers\">Fun With <code>SoupStrainer</code>s</a></li></li>\\n<li><a href=\"#Improving Performance by Parsing Only Part of the Document\">Improving Performance by Parsing Only Part of the Document</a></li></li>\\n<li><a href=\"#Improving Memory Usage with extract\">Improving Memory Usage with <code>extract</code></a></li></li>\\n</ul>\\n<li><a href=\"#See Also\">See Also</a></li></li>\\n<ul>\\n<li><a href=\"#Applications that use Beautiful Soup\">Applications that use Beautiful Soup</a></li></li>\\n<li><a href=\"#Similar libraries\">Similar libraries</a></li></li>\\n</ul>\\n<li><a href=\"#Conclusion\">Conclusion</a></li></li>\\n</ul>\\n\\n<a name=\"Quick Start\"><h2>Quick Start</h2></a>\\n\\n<p>Get Beautiful Soup <a\\nhref=\"http://www.crummy.com/software/BeautifulSoup/#Download/\">here</a>. The\\n<a\\nhref=\"http://www.crummy.com/software/BeautifulSoup/CHANGELOG.html\">changelog</a>\\ndescribes differences between 3.0 and earlier versions.\\n\\n<p>Include Beautiful Soup in your application with a line like one of\\nthe following:\\n\\n<div class=\"sample\"><pre>\\n<kbd>from BeautifulSoup import BeautifulSoup          # For processing HTML</kbd>\\n<kbd>from BeautifulSoup import BeautifulStoneSoup     # For processing XML</kbd>\\n<kbd>import BeautifulSoup                             # To get everything</kbd>\\n</pre></div>\\n\\n<p>If you get the message \"No module named BeautifulSoup\", but you\\nknow Beautiful Soup is installed, you\\'re probably using the Beautiful\\nSoup 4 beta. Use this code instead:\\n\\n<div class=\"sample\"><pre>\\n<kbd>from bs4 import BeautifulSoup # To get everything</kbd>\\n</pre></div>\\n\\n<p>This document only covers Beautiful Soup 3. Beautiful Soup 4 has some slight differences; see the README.txt file for details.\\n\\n<p>Here\\'s some code demonstrating the basic features of Beautiful\\nSoup. You can copy and paste this code into a Python session to run it\\nyourself.\\n\\n<div class=\"sample\"><pre>\\n<kbd>from BeautifulSoup import BeautifulSoup</kbd>\\n<kbd>import re</kbd>\\n<kbd></kbd>\\n<kbd>doc = [\\'&lt;html&gt;&lt;head&gt;&lt;title&gt;Page title&lt;/title&gt;&lt;/head&gt;\\',</kbd>\\n<kbd>       \\'&lt;body&gt;&lt;p id=\"firstpara\" align=\"center\"&gt;This is paragraph &lt;b&gt;one&lt;/b&gt;.\\',</kbd>\\n<kbd>       \\'&lt;p id=\"secondpara\" align=\"blah\"&gt;This is paragraph &lt;b&gt;two&lt;/b&gt;.\\',</kbd>\\n<kbd>       \\'&lt;/html&gt;\\']</kbd>\\n<kbd>soup = BeautifulSoup(\\'\\'.join(doc))</kbd>\\n<kbd></kbd>\\n<kbd>print soup.prettify()</kbd>\\n# <samp>&lt;html&gt;</samp>\\n# <samp> &lt;head&gt;</samp>\\n# <samp>  &lt;title&gt;</samp>\\n# <samp>   Page title</samp>\\n# <samp>  &lt;/title&gt;</samp>\\n# <samp> &lt;/head&gt;</samp>\\n# <samp> &lt;body&gt;</samp>\\n# <samp>  &lt;p id=\"firstpara\" align=\"center\"&gt;</samp>\\n# <samp>   This is paragraph</samp>\\n# <samp>   &lt;b&gt;</samp>\\n# <samp>    one</samp>\\n# <samp>   &lt;/b&gt;</samp>\\n# <samp>   .</samp>\\n# <samp>  &lt;/p&gt;</samp>\\n# <samp>  &lt;p id=\"secondpara\" align=\"blah\"&gt;</samp>\\n# <samp>   This is paragraph</samp>\\n# <samp>   &lt;b&gt;</samp>\\n# <samp>    two</samp>\\n# <samp>   &lt;/b&gt;</samp>\\n# <samp>   .</samp>\\n# <samp>  &lt;/p&gt;</samp>\\n# <samp> &lt;/body&gt;</samp>\\n# <samp>&lt;/html&gt;</samp>\\n</pre></div>\\n\\n<p>Here are some ways to navigate the soup:\\n\\n<div class=\"sample\"><pre>\\n<kbd>soup.contents[0].name</kbd>\\n# <samp>u\\'html\\'</samp>\\n<kbd></kbd>\\n<kbd>soup.contents[0].contents[0].name</kbd>\\n# <samp>u\\'head\\'</samp>\\n<kbd></kbd>\\n<kbd>head = soup.contents[0].contents[0]</kbd>\\n<kbd>head.parent.name</kbd>\\n# <samp>u\\'html\\'</samp>\\n<kbd></kbd>\\n<kbd>head.next</kbd>\\n# <samp>&lt;title&gt;Page title&lt;/title&gt;</samp>\\n<kbd></kbd>\\n<kbd>head.nextSibling.name</kbd>\\n# <samp>u\\'body\\'</samp>\\n<kbd></kbd>\\n<kbd>head.nextSibling.contents[0]</kbd>\\n# <samp>&lt;p id=\"firstpara\" align=\"center\"&gt;This is paragraph &lt;b&gt;one&lt;/b&gt;.&lt;/p&gt;</samp>\\n<kbd></kbd>\\n<kbd>head.nextSibling.contents[0].nextSibling</kbd>\\n# <samp>&lt;p id=\"secondpara\" align=\"blah\"&gt;This is paragraph &lt;b&gt;two&lt;/b&gt;.&lt;/p&gt;</samp>\\n</pre></div>\\n\\n<p>Here are a couple of ways to search the soup for certain tags, or\\ntags with certain properties:\\n\\n<div class=\"sample\"><pre>\\n<kbd>titleTag = soup.html.head.title</kbd>\\n<kbd>titleTag</kbd>\\n# <samp>&lt;title&gt;Page title&lt;/title&gt;</samp>\\n<kbd></kbd>\\n<kbd>titleTag.string</kbd>\\n# <samp>u\\'Page title\\'</samp>\\n<kbd></kbd>\\n<kbd>len(soup(\\'p\\'))</kbd>\\n# <samp>2</samp>\\n<kbd></kbd>\\n<kbd>soup.findAll(\\'p\\', align=\"center\")</kbd>\\n# <samp>[&lt;p id=\"firstpara\" align=\"center\"&gt;This is paragraph &lt;b&gt;one&lt;/b&gt;. &lt;/p&gt;]</samp>\\n<kbd></kbd>\\n<kbd>soup.find(\\'p\\', align=\"center\")</kbd>\\n# <samp>&lt;p id=\"firstpara\" align=\"center\"&gt;This is paragraph &lt;b&gt;one&lt;/b&gt;. &lt;/p&gt;</samp>\\n<kbd></kbd>\\n<kbd>soup(\\'p\\', align=\"center\")[0][\\'id\\']</kbd>\\n# <samp>u\\'firstpara\\'</samp>\\n<kbd></kbd>\\n<kbd>soup.find(\\'p\\', align=re.compile(\\'^b.*\\'))[\\'id\\']</kbd>\\n# <samp>u\\'secondpara\\'</samp>\\n<kbd></kbd>\\n<kbd>soup.find(\\'p\\').b.string</kbd>\\n# <samp>u\\'one\\'</samp>\\n<kbd></kbd>\\n<kbd>soup(\\'p\\')[1].b.string</kbd>\\n# <samp>u\\'two\\'</samp>\\n</pre></div>\\n\\n<p>It\\'s easy to modify the soup:\\n\\n<div class=\"sample\"><pre>\\n<kbd>titleTag[\\'id\\'] = \\'theTitle\\'</kbd>\\n<kbd>titleTag.contents[0].replaceWith(\"New title\")</kbd>\\n<kbd>soup.html.head</kbd>\\n# <samp>&lt;head&gt;&lt;title id=\"theTitle\"&gt;New title&lt;/title&gt;&lt;/head&gt;</samp>\\n<kbd></kbd>\\n<kbd>soup.p.extract()</kbd>\\n<kbd>soup.prettify()</kbd>\\n# <samp>&lt;html&gt;</samp>\\n# <samp> &lt;head&gt;</samp>\\n# <samp>  &lt;title id=\"theTitle\"&gt;</samp>\\n# <samp>   New title</samp>\\n# <samp>  &lt;/title&gt;</samp>\\n# <samp> &lt;/head&gt;</samp>\\n# <samp> &lt;body&gt;</samp>\\n# <samp>  &lt;p id=\"secondpara\" align=\"blah\"&gt;</samp>\\n# <samp>   This is paragraph</samp>\\n# <samp>   &lt;b&gt;</samp>\\n# <samp>    two</samp>\\n# <samp>   &lt;/b&gt;</samp>\\n# <samp>   .</samp>\\n# <samp>  &lt;/p&gt;</samp>\\n# <samp> &lt;/body&gt;</samp>\\n# <samp>&lt;/html&gt;</samp>\\n<kbd></kbd>\\n<kbd>soup.p.replaceWith(soup.b)</kbd>\\n# <samp>&lt;html&gt;</samp>\\n# <samp> &lt;head&gt;</samp>\\n# <samp>  &lt;title id=\"theTitle\"&gt;</samp>\\n# <samp>   New title</samp>\\n# <samp>  &lt;/title&gt;</samp>\\n# <samp> &lt;/head&gt;</samp>\\n# <samp> &lt;body&gt;</samp>\\n# <samp>  &lt;b&gt;</samp>\\n# <samp>   two</samp>\\n# <samp>  &lt;/b&gt;</samp>\\n# <samp> &lt;/body&gt;</samp>\\n# <samp>&lt;/html&gt;</samp>\\n<kbd></kbd>\\n<kbd>soup.body.insert(0, \"This page used to have \")</kbd>\\n<kbd>soup.body.insert(2, \" &amp;lt;p&amp;gt; tags!\")</kbd>\\n<kbd>soup.body</kbd>\\n# <samp>&lt;body&gt;This page used to have &lt;b&gt;two&lt;/b&gt; &amp;lt;p&amp;gt; tags!&lt;/body&gt;</samp>\\n</pre></div>\\n\\n<p>Here\\'s a real-world example. It fetches the <a\\nhref=\"http://www.icc-ccs.org/prc/piracyreport.php\">ICC Commercial\\nCrime Services weekly piracy report</a>, parses it with Beautiful\\nSoup, and pulls out the piracy incidents:\\n\\n<div class=\"sample\"><pre>\\n<kbd>import urllib2</kbd>\\n<kbd>from BeautifulSoup import BeautifulSoup</kbd>\\n<kbd></kbd>\\n<kbd>page = urllib2.urlopen(\"http://www.icc-ccs.org/prc/piracyreport.php\")</kbd>\\n<kbd>soup = BeautifulSoup(page)</kbd>\\n<kbd>for incident in soup(\\'td\\', width=\"90%\"):</kbd>\\n<kbd>    where, linebreak, what = incident.contents[:3]</kbd>\\n<kbd>    print where.strip()</kbd>\\n<kbd>    print what.strip()</kbd>\\n<kbd>    print</kbd>\\n</pre></div>\\n\\n<a name=\"Parsing a Document\"><h2>Parsing a Document</h2></a>\\n\\n<p>A Beautiful Soup constructor takes an XML or HTML document in the\\nform of a string (or an open file-like object). It parses the document\\nand creates a corresponding data structure in memory.\\n\\n<p>If you give Beautiful Soup a perfectly-formed document, the parsed\\ndata structure looks just like the original document. But if there\\'s\\nsomething wrong with the document, Beautiful Soup uses heuristics to\\nfigure out a reasonable structure for the data structure.\\n\\n<a name=\"Parsing HTML\"><h3>Parsing HTML</h3></a>\\n\\n<p>Use the <code>BeautifulSoup</code> class to parse an HTML\\ndocument. Here are some of the things that <code>BeautifulSoup</code>\\nknows:\\n\\n<ul>\\n<li>Some tags can be nested (&lt;BLOCKQUOTE&gt;) and some can\\'t (&lt;P&gt;).\\n<li>Table and list tags have a natural nesting order. For instance,\\n&lt;TD&gt; tags go inside &lt;TR&gt; tags, not the other way around.\\n<li>The contents of a &lt;SCRIPT&gt; tag should not be parsed as HTML.\\n<li>A &lt;META&gt; tag may specify an encoding for the document.\\n</ul>\\n\\n<p>Here it is in action:\\n\\n<div class=\"sample\"><pre>\\n<kbd>from BeautifulSoup import BeautifulSoup</kbd>\\n<kbd>html = \"&lt;html&gt;&lt;p&gt;Para 1&lt;p&gt;Para 2&lt;blockquote&gt;Quote 1&lt;blockquote&gt;Quote 2\"</kbd>\\n<kbd>soup = BeautifulSoup(html)</kbd>\\n<kbd>print soup.prettify()</kbd>\\n# <samp>&lt;html&gt;</samp>\\n# <samp> &lt;p&gt;</samp>\\n# <samp>  Para 1</samp>\\n# <samp> &lt;/p&gt;</samp>\\n# <samp> &lt;p&gt;</samp>\\n# <samp>  Para 2</samp>\\n# <samp>  &lt;blockquote&gt;</samp>\\n# <samp>   Quote 1</samp>\\n# <samp>   &lt;blockquote&gt;</samp>\\n# <samp>    Quote 2</samp>\\n# <samp>   &lt;/blockquote&gt;</samp>\\n# <samp>  &lt;/blockquote&gt;</samp>\\n# <samp> &lt;/p&gt;</samp>\\n# <samp>&lt;/html&gt;</samp>\\n</pre></div>\\n\\n<p>Note that <code>BeautifulSoup</code> figured out sensible places to put the\\nclosing tags, even though the original document lacked them.\\n\\n<p>That document isn\\'t valid HTML, but it\\'s not too bad either. Here\\'s\\na really horrible document. Among other problems, it\\'s got a &lt;FORM&gt;\\ntag that starts outside of a &lt;TABLE&gt; tag and ends inside the &lt;TABLE&gt;\\ntag. (HTML like this was found on a website run by a major web\\ncompany.)\\n\\n<div class=\"sample\"><pre>\\n<kbd>from BeautifulSoup import BeautifulSoup</kbd>\\n<kbd>html = \"\"\"</kbd>\\n<kbd>&lt;html&gt;</kbd>\\n<kbd>&lt;form&gt;</kbd>\\n<kbd> &lt;table&gt;</kbd>\\n<kbd> &lt;td&gt;&lt;input name=\"input1\"&gt;Row 1 cell 1</kbd>\\n<kbd> &lt;tr&gt;&lt;td&gt;Row 2 cell 1</kbd>\\n<kbd> &lt;/form&gt; </kbd>\\n<kbd> &lt;td&gt;Row 2 cell 2&lt;br&gt;This&lt;/br&gt; sure is a long cell</kbd>\\n<kbd>&lt;/body&gt; </kbd>\\n<kbd>&lt;/html&gt;\"\"\"</kbd>\\n</pre></div>\\n\\n<p>Beautiful Soup handles this document as well:\\n\\n<div class=\"sample\"><pre>\\n<kbd>print BeautifulSoup(html).prettify()</kbd>\\n# <samp>&lt;html&gt;</samp>\\n# <samp> &lt;form&gt;</samp>\\n# <samp>  &lt;table&gt;</samp>\\n# <samp>   &lt;td&gt;</samp>\\n# <samp>    &lt;input name=\"input1\" /&gt;</samp>\\n# <samp>    Row 1 cell 1</samp>\\n# <samp>   &lt;/td&gt;</samp>\\n# <samp>   &lt;tr&gt;</samp>\\n# <samp>    &lt;td&gt;</samp>\\n# <samp>     Row 2 cell 1</samp>\\n# <samp>    &lt;/td&gt;</samp>\\n# <samp>   &lt;/tr&gt;</samp>\\n# <samp>  &lt;/table&gt;</samp>\\n# <samp> &lt;/form&gt;</samp>\\n# <samp> &lt;td&gt;</samp>\\n# <samp>  Row 2 cell 2</samp>\\n# <samp>  &lt;br /&gt;</samp>\\n# <samp>  This </samp>\\n# <samp>  sure is a long cell</samp>\\n# <samp> &lt;/td&gt;</samp>\\n# <samp>&lt;/html&gt;</samp>\\n</pre></div>\\n\\n<p>The last cell of the table is outside the &lt;TABLE&gt; tag; Beautiful\\nSoup decided to close the &lt;TABLE&gt; tag when it closed the &lt;FORM&gt;\\ntag. The author of the original document probably intended the &lt;FORM&gt;\\ntag to extend to the end of the table, but Beautiful Soup has no way\\nof knowing that. Even in a bizarre case like this, Beautiful Soup\\nparses the invalid document and gives you access to all the data.\\n\\n<a name=\"Parsing XML\"><h3>Parsing XML</h3></a>\\n\\n<p>The <code>BeautifulSoup</code> class is full of web-browser-like\\nheuristics for divining the intent of HTML authors. But XML doesn\\'t\\nhave a fixed tag set, so those heuristics don\\'t apply.  So\\n<code>BeautifulSoup</code> doesn\\'t do XML very well.\\n\\n<p>Use the <code>BeautifulStoneSoup</code> class to parse XML\\ndocuments. It\\'s a general class with no special knowledge of any XML\\ndialect and very simple rules about tag nesting: Here it is in action:\\n\\n<div class=\"sample\"><pre>\\n<kbd>from BeautifulSoup import BeautifulStoneSoup</kbd>\\n<kbd>xml = \"&lt;doc&gt;&lt;tag1&gt;Contents 1&lt;tag2&gt;Contents 2&lt;tag1&gt;Contents 3\"</kbd>\\n<kbd>soup = BeautifulStoneSoup(xml)</kbd>\\n<kbd>print soup.prettify()</kbd>\\n# <samp>&lt;doc&gt;</samp>\\n# <samp> &lt;tag1&gt;</samp>\\n# <samp>  Contents 1</samp>\\n# <samp>  &lt;tag2&gt;</samp>\\n# <samp>   Contents 2</samp>\\n# <samp>  &lt;/tag2&gt;</samp>\\n# <samp> &lt;/tag1&gt;</samp>\\n# <samp> &lt;tag1&gt;</samp>\\n# <samp>  Contents 3</samp>\\n# <samp> &lt;/tag1&gt;</samp>\\n# <samp>&lt;/doc&gt;</samp>\\n</pre></div>\\n\\n<p><a name=\"selfClosingTags\">The</a> most common shortcoming of\\n<code>BeautifulStoneSoup</code> is that it doesn\\'t know about\\nself-closing tags. HTML has a fixed set of self-closing tags, but with\\nXML it depends on what the DTD says. You can tell\\n<code>BeautifulStoneSoup</code> that certain tags are self-closing by\\npassing in their names as the <code>selfClosingTags</code> argument to\\nthe constructor:\\n\\n<div class=\"sample\"><pre>\\n<kbd>from BeautifulSoup import BeautifulStoneSoup</kbd>\\n<kbd>xml = \"&lt;tag&gt;Text 1&lt;selfclosing&gt;Text 2\"</kbd>\\n<kbd>print BeautifulStoneSoup(xml).prettify()</kbd>\\n# <samp>&lt;tag&gt;</samp>\\n# <samp> Text 1</samp>\\n# <samp> &lt;selfclosing&gt;</samp>\\n# <samp>  Text 2</samp>\\n# <samp> &lt;/selfclosing&gt;</samp>\\n# <samp>&lt;/tag&gt;</samp>\\n<kbd></kbd>\\n<kbd>print BeautifulStoneSoup(xml, selfClosingTags=[\\'selfclosing\\']).prettify()</kbd>\\n# <samp>&lt;tag&gt;</samp>\\n# <samp> Text 1</samp>\\n# <samp> &lt;selfclosing /&gt;</samp>\\n# <samp> Text 2</samp>\\n# <samp>&lt;/tag&gt;</samp>\\n</pre></div>\\n\\n<a name=\"If That Doesn\\'t Work\"><h3>If That Doesn\\'t Work</h3></a>\\n\\n<p>There are several <a href=\"#Other Built-In Parsers\">other parser classes</a>\\nwith different heuristics from these two. You can also <a\\nhref=\"#Customizing the Parser\">subclass and customize a parser</a> and\\ngive it your own heuristics.\\n\\n<a name=\"Beautiful Soup Gives You Unicode, Dammit\"><h2>Beautiful Soup Gives You Unicode, Dammit</h2></a>\\n\\n<p>By the time your document is parsed, it has been transformed into\\nUnicode. Beautiful Soup stores only Unicode strings in its data\\nstructures.\\n\\n<div class=\"sample\"><pre>\\n<kbd>from BeautifulSoup import BeautifulSoup</kbd>\\n<kbd>soup = BeautifulSoup(\"Hello\")</kbd>\\n<kbd>soup.contents[0]</kbd>\\n# <samp>u\\'Hello\\'</samp>\\n<kbd>soup.originalEncoding</kbd>\\n# <samp>\\'ascii\\'</samp>\\n</pre></div>\\n\\n<p>Here\\'s an example with a Japanese document encoded in UTF-8:\\n\\n<div class=\"sample\"><pre>\\n<kbd>from BeautifulSoup import BeautifulSoup</kbd>\\n<kbd>soup = BeautifulSoup(\"\\\\xe3\\\\x81\\\\x93\\\\xe3\\\\x82\\\\x8c\\\\xe3\\\\x81\\\\xaf\")</kbd>\\n<kbd>soup.contents[0]</kbd>\\n# <samp>u\\'\\\\u3053\\\\u308c\\\\u306f\\'</samp>\\n<kbd>soup.originalEncoding</kbd>\\n# <samp>\\'utf-8\\'</samp>\\n<kbd></kbd>\\n<kbd>str(soup)</kbd>\\n# <samp>\\'\\\\xe3\\\\x81\\\\x93\\\\xe3\\\\x82\\\\x8c\\\\xe3\\\\x81\\\\xaf\\'</samp>\\n<kbd></kbd>\\n# <samp>Note: this bit uses EUC-JP, so it only works if you have cjkcodecs</samp>\\n# <samp>installed, or are running Python 2.4.</samp>\\n<kbd>soup.__str__(\\'euc-jp\\')</kbd>\\n# <samp>\\'\\\\xa4\\\\xb3\\\\xa4\\\\xec\\\\xa4\\\\xcf\\'</samp>\\n</pre></div>\\n\\n<p>Beautiful Soup uses a class called <code>UnicodeDammit</code> to\\ndetect the encodings of documents you give it and convert them to\\nUnicode, no matter what. If you need to do this for other documents\\n(without using Beautiful Soup to parse them), you can use\\n<code>UnicodeDammit</code> by itself. It\\'s heavily based on code from\\nthe <a href=\"http://www.feedparser.org/\">Universal Feed Parser</a>.\\n\\n<p>If you\\'re running an older version of Python than 2.4, be sure to\\ndownload and install <a\\nhref=\"http://cjkpython.i18n.org/\"><code>cjkcodecs</code> and\\n<code>iconvcodec</code></a>, which make Python capable of supporting\\nmore codecs, especially CJK codecs. Also install the <a\\nhref=\"http://chardet.feedparser.org/\"><code>chardet</code></a>\\nlibrary, for better autodetection.\\n\\n<p>Beautiful Soup tries the following encodings, in order of priority,\\nto turn your document into Unicode:\\n\\n<ul>\\n\\n<li>An encoding you pass in as the <code>fromEncoding</code> argument\\nto the soup constructor.\\n\\n<li>An encoding discovered in the document itself: for instance, in an\\nXML declaration or (for HTML documents) an <code>http-equiv</code>\\nMETA tag. If Beautiful Soup finds this kind of encoding within the\\ndocument, it parses the document again from the beginning and gives\\nthe new encoding a try. The only exception is if you explicitly\\nspecified an encoding, and that encoding actually worked: then it will\\nignore any encoding it finds in the document.\\n\\n<li>An encoding sniffed by looking at the first few bytes of the\\nfile. If an encoding is detected at this stage, it will be one of the\\nUTF-* encodings, EBCDIC, or ASCII.\\n\\n<li>An encoding sniffed by the <a\\nhref=\"http://chardet.feedparser.org/\"><code>chardet</code></a>\\nlibrary, if you have it installed.\\n<li>UTF-8\\n<li>Windows-1252\\n</ul>\\n\\n<p>Beautiful Soup will almost always guess right if it can make a\\nguess at all. But for documents with no declarations and in strange\\nencodings, it will often not be able to guess. It will fall back to\\nWindows-1252, which will probably be wrong. Here\\'s an EUC-JP example\\nwhere Beautiful Soup guesses the encoding wrong. (Again, because it\\nuses EUC-JP, this example will only work if you are running Python 2.4\\nor have <code>cjkcodecs</code> installed):\\n\\n<div class=\"sample\"><pre>\\n<kbd>from BeautifulSoup import BeautifulSoup</kbd>\\n<kbd>euc_jp = \\'\\\\xa4\\\\xb3\\\\xa4\\\\xec\\\\xa4\\\\xcf\\'</kbd>\\n<kbd></kbd>\\n<kbd>soup = BeautifulSoup(euc_jp)</kbd>\\n<kbd>soup.originalEncoding</kbd>\\n# <samp>\\'windows-1252\\'</samp>\\n<kbd></kbd>\\n<kbd>str(soup)</kbd>\\n# <samp>\\'\\\\xc2\\\\xa4\\\\xc2\\\\xb3\\\\xc2\\\\xa4\\\\xc3\\\\xac\\\\xc2\\\\xa4\\\\xc3\\\\x8f\\'     # Wrong!</samp>\\n</pre></div>\\n\\n<p>But if you specify the encoding with <code>fromEncoding</code>, it\\nparses the document correctly, and can convert it to UTF-8 or back to\\nEUC-JP.\\n\\n<div class=\"sample\"><pre>\\n<kbd>soup = BeautifulSoup(euc_jp, fromEncoding=\"euc-jp\")</kbd>\\n<kbd>soup.originalEncoding</kbd>\\n# <samp>\\'windows-1252\\'</samp>\\n<kbd></kbd>\\n<kbd>str(soup)</kbd>\\n# <samp>\\'\\\\xe3\\\\x81\\\\x93\\\\xe3\\\\x82\\\\x8c\\\\xe3\\\\x81\\\\xaf\\'                 # Right!</samp>\\n<kbd></kbd>\\n<kbd>soup.__str__(self, \\'euc-jp\\') == euc_jp</kbd>\\n# <samp>True</samp>\\n</pre></div>\\n\\n<p>If you give Beautiful Soup a document in the Windows-1252 encoding\\n(or a similar encoding like ISO-8859-1 or ISO-8859-2), Beautiful Soup\\nfinds and destroys the document\\'s smart quotes and other\\nWindows-specific characters. Rather than transforming those characters\\ninto their Unicode equivalents, Beautiful Soup transforms them into\\nHTML entities (<code>BeautifulSoup</code>) or XML entities\\n(<code>BeautifulStoneSoup</code>).\\n\\n<p>To prevent this, you can pass <code>smartQuotesTo=None</code> into the soup\\nconstructor: then smart quotes will be converted to Unicode like any\\nother native-encoding characters. You can also pass in \"xml\" or \"html\"\\nfor <code>smartQuotesTo</code>, to change the default behavior of <code>BeautifulSoup</code>\\nand <code>BeautifulStoneSoup</code>.\\n\\n<div class=\"sample\"><pre>\\n<kbd>from BeautifulSoup import BeautifulSoup, BeautifulStoneSoup</kbd>\\n<kbd>text = \"Deploy the \\\\x91SMART QUOTES\\\\x92!\"</kbd>\\n<kbd></kbd>\\n<kbd>str(BeautifulSoup(text))</kbd>\\n# <samp>\\'Deploy the &amp;lsquo;SMART QUOTES&amp;rsquo;!\\'</samp>\\n<kbd></kbd>\\n<kbd>str(BeautifulStoneSoup(text))</kbd>\\n# <samp>\\'Deploy the &amp;#x2018;SMART QUOTES&amp;#x2019;!\\'</samp>\\n<kbd></kbd>\\n<kbd>str(BeautifulSoup(text, smartQuotesTo=\"xml\"))</kbd>\\n# <samp>\\'Deploy the &amp;#x2018;SMART QUOTES&amp;#x2019;!\\'</samp>\\n<kbd></kbd>\\n<kbd>BeautifulSoup(text, smartQuotesTo=None).contents[0]</kbd>\\n# <samp>u\\'Deploy the \\\\u2018SMART QUOTES\\\\u2019!\\'</samp>\\n</pre></div>\\n\\n<a name=\"Printing a Document\"><h2>Printing a Document</h2></a>\\n\\n<p>You can turn a Beautiful Soup document (or any subset of it) into a\\nstring with the <code>str</code> function, or the <code>prettify</code> or <code>renderContents</code>\\nmethods. You can also use the <code>unicode</code> function to get the whole\\ndocument as a Unicode string.\\n\\n<p>The <code>prettify</code> method adds strategic newlines and spacing to make\\nthe structure of the document obvious. It also strips out text nodes\\nthat contain only whitespace, which might change the meaning of an XML\\ndocument. The <code>str</code> and <code>unicode</code> functions don\\'t strip out text nodes\\nthat contain only whitespace, and they don\\'t add any whitespace\\nbetween nodes either.\\n\\n<p>Here\\'s an example.\\n\\n<div class=\"sample\"><pre>\\n<kbd>from BeautifulSoup import BeautifulSoup</kbd>\\n<kbd>doc = \"&lt;html&gt;&lt;h1&gt;Heading&lt;/h1&gt;&lt;p&gt;Text\"</kbd>\\n<kbd>soup = BeautifulSoup(doc)</kbd>\\n<kbd></kbd>\\n<kbd>str(soup)</kbd>\\n# <samp>\\'&lt;html&gt;&lt;h1&gt;Heading&lt;/h1&gt;&lt;p&gt;Text&lt;/p&gt;&lt;/html&gt;\\'</samp>\\n<kbd>soup.renderContents()</kbd>\\n# <samp>\\'&lt;html&gt;&lt;h1&gt;Heading&lt;/h1&gt;&lt;p&gt;Text&lt;/p&gt;&lt;/html&gt;\\'</samp>\\n<kbd>soup.__str__()</kbd>\\n# <samp>\\'&lt;html&gt;&lt;h1&gt;Heading&lt;/h1&gt;&lt;p&gt;Text&lt;/p&gt;&lt;/html&gt;\\'</samp>\\n<kbd>unicode(soup)</kbd>\\n# <samp>u\\'&lt;html&gt;&lt;h1&gt;Heading&lt;/h1&gt;&lt;p&gt;Text&lt;/p&gt;&lt;/html&gt;\\'</samp>\\n<kbd></kbd>\\n<kbd>soup.prettify()</kbd>\\n# <samp>\\'&lt;html&gt;\\\\n &lt;h1&gt;\\\\n  Heading\\\\n &lt;/h1&gt;\\\\n &lt;p&gt;\\\\n  Text\\\\n &lt;/p&gt;\\\\n&lt;/html&gt;\\'</samp>\\n<kbd></kbd>\\n<kbd>print soup.prettify()</kbd>\\n# <samp>&lt;html&gt;</samp>\\n# <samp> &lt;h1&gt;</samp>\\n# <samp>  Heading</samp>\\n# <samp> &lt;/h1&gt;</samp>\\n# <samp> &lt;p&gt;</samp>\\n# <samp>  Text</samp>\\n# <samp> &lt;/p&gt;</samp>\\n# <samp>&lt;/html&gt;</samp>\\n</pre></div>\\n\\n<p>Note that <code>str</code> and <code>renderContents</code> give\\ndifferent results when used on a tag within the document.\\n<code>str</code> prints a tag and its contents, and\\n<code>renderContents</code> only prints the contents.\\n\\n<div class=\"sample\"><pre>\\n<kbd>heading = soup.h1</kbd>\\n<kbd>str(heading)</kbd>\\n# <samp>\\'&lt;h1&gt;Heading&lt;/h1&gt;\\'</samp>\\n<kbd>heading.renderContents()</kbd>\\n# <samp>\\'Heading\\'</samp>\\n</pre></div>\\n\\n<p>When you call <code>__str__</code>, <code>prettify</code>, or\\n<code>renderContents</code>, you can specify an output encoding. The\\ndefault encoding (the one used by <code>str</code>) is UTF-8. Here\\'s\\nan example that parses an ISO-8851-1 string and then outputs the same\\nstring in different encodings:\\n\\n<div class=\"sample\"><pre>\\n<kbd>from BeautifulSoup import BeautifulSoup</kbd>\\n<kbd>doc = \"Sacr\\\\xe9 bleu!\"</kbd>\\n<kbd>soup = BeautifulSoup(doc)</kbd>\\n<kbd>str(soup)</kbd>\\n# <samp>\\'Sacr\\\\xc3\\\\xa9 bleu!\\'                          # UTF-8</samp>\\n<kbd>soup.__str__(\"ISO-8859-1\")</kbd>\\n# <samp>\\'Sacr\\\\xe9 bleu!\\'</samp>\\n<kbd>soup.__str__(\"UTF-16\")</kbd>\\n# <samp>\\'\\\\xff\\\\xfeS\\\\x00a\\\\x00c\\\\x00r\\\\x00\\\\xe9\\\\x00 \\\\x00b\\\\x00l\\\\x00e\\\\x00u\\\\x00!\\\\x00\\'</samp>\\n<kbd>soup.__str__(\"EUC-JP\")</kbd>\\n# <samp>\\'Sacr\\\\x8f\\\\xab\\\\xb1 bleu!\\'</samp>\\n</pre></div>\\n\\n<p>If the original document contained an encoding declaration, then\\nBeautiful Soup rewrites the declaration to mention the new encoding\\nwhen it converts the document back to a string. This means that if you\\nload an HTML document into <code>BeautifulSoup</code> and print it\\nback out, not only should the HTML be cleaned up, but it should be\\ntransparently converted to UTF-8.\\n\\n<p>Here\\'s an HTML example:\\n\\n<div class=\"sample\"><pre>\\n<kbd>from BeautifulSoup import BeautifulSoup</kbd>\\n<kbd>doc = \"\"\"&lt;html&gt;</kbd>\\n<kbd>&lt;meta http-equiv=\"Content-type\" content=\"text/html; charset=ISO-Latin-1\" &gt;</kbd>\\n<kbd>Sacr\\\\xe9 bleu!</kbd>\\n<kbd>&lt;/html&gt;\"\"\"</kbd>\\n<kbd></kbd>\\n<kbd>print BeautifulSoup(doc).prettify()</kbd>\\n# <samp>&lt;html&gt;</samp>\\n# <samp> &lt;meta http-equiv=\"Content-type\" content=\"text/html; charset=utf-8\" /&gt;</samp>\\n# <samp> Sacr&eacute; bleu!</samp>\\n# <samp>&lt;/html&gt;</samp>\\n</pre></div>\\n\\n<p>Here\\'s an XML example:\\n\\n<div class=\"sample\"><pre>\\n<kbd>from BeautifulSoup import BeautifulStoneSoup</kbd>\\n<kbd>doc = \"\"\"&lt;?xml version=\"1.0\" encoding=\"ISO-Latin-1\"&gt;Sacr\\\\xe9 bleu!\"\"\"</kbd>\\n<kbd></kbd>\\n<kbd>print BeautifulStoneSoup(doc).prettify()</kbd>\\n# <samp>&lt;?xml version=\\'1.0\\' encoding=\\'utf-8\\'&gt;</samp>\\n# <samp>Sacr&eacute; bleu!</samp>\\n</pre></div>\\n\\n<a name=\"The Parse Tree\"><h2>The Parse Tree</h2></a>\\n\\n<p>So far we\\'ve focused on loading documents and writing them back\\nout. Most of the time, though, you\\'re interested in the parse tree:\\nthe data structure Beautiful Soup builds as it parses the document.\\n\\n<p>A parser object (an instance of <code>BeautifulSoup</code> or\\n<code>BeautifulStoneSoup</code>) is a deeply-nested, well-connected data\\nstructure that corresponds to the structure of an XML or HTML\\ndocument. The parser object contains two other types of objects: <code>Tag</code>\\nobjects, which correspond to tags like the &lt;TITLE&gt; tag and the &lt;B&gt;\\ntags; and <code>NavigableString</code> objects, which correspond to strings like\\n\"Page title\" and \"This is paragraph\".\\n\\n<p>There are also some subclasses of <code>NavigableString</code> (<code>CData</code>,\\n<code>Comment</code>, <code>Declaration</code>, and <code>ProcessingInstruction</code>), which\\ncorrespond to special XML constructs. They act like\\n<code>NavigableString</code>s, except that when it\\'s time to print them out they\\nhave some extra data attached to them. Here\\'s a document that includes\\na comment:\\n\\n<div class=\"sample\"><pre>\\n<kbd>from BeautifulSoup import BeautifulSoup</kbd>\\n<kbd>import re</kbd>\\n<kbd>hello = \"Hello! &lt;!--I\\'ve got to be nice to get what I want.--&gt;\"</kbd>\\n<kbd>commentSoup = BeautifulSoup(hello)</kbd>\\n<kbd>comment = commentSoup.find(text=re.compile(\"nice\"))</kbd>\\n<kbd></kbd>\\n<kbd>comment.__class__</kbd>\\n# <samp>&lt;class \\'BeautifulSoup.Comment\\'&gt;</samp>\\n<kbd>comment</kbd>\\n# <samp>u\"I\\'ve got to be nice to get what I want.\"</samp>\\n<kbd>comment.previousSibling</kbd>\\n# <samp>u\\'Hello! \\'</samp>\\n<kbd></kbd>\\n<kbd>str(comment)</kbd>\\n# <samp>\"&lt;!--I\\'ve got to be nice to get what I want.--&gt;\"</samp>\\n<kbd>print commentSoup</kbd>\\n# <samp>Hello! &lt;!--I\\'ve got to be nice to get what I want.--&gt;</samp>\\n</pre></div>\\n\\n<p>Now, let\\'s take <a name=\"The document above\">a closer look</a> at\\nthe document used at the beginning of the documentation:\\n\\n<div class=\"sample\"><pre>\\n<kbd>from BeautifulSoup import BeautifulSoup </kbd>\\n<kbd>doc = [\\'&lt;html&gt;&lt;head&gt;&lt;title&gt;Page title&lt;/title&gt;&lt;/head&gt;\\',</kbd>\\n<kbd>       \\'&lt;body&gt;&lt;p id=\"firstpara\" align=\"center\"&gt;This is paragraph &lt;b&gt;one&lt;/b&gt;.\\',</kbd>\\n<kbd>       \\'&lt;p id=\"secondpara\" align=\"blah\"&gt;This is paragraph &lt;b&gt;two&lt;/b&gt;.\\',</kbd>\\n<kbd>       \\'&lt;/html&gt;\\']</kbd>\\n<kbd>soup = BeautifulSoup(\\'\\'.join(doc))</kbd>\\n<kbd></kbd>\\n<kbd>print soup.prettify()</kbd>\\n# <samp>&lt;html&gt;</samp>\\n# <samp> &lt;head&gt;</samp>\\n# <samp>  &lt;title&gt;</samp>\\n# <samp>   Page title</samp>\\n# <samp>  &lt;/title&gt;</samp>\\n# <samp> &lt;/head&gt;</samp>\\n# <samp> &lt;body&gt;</samp>\\n# <samp>  &lt;p id=\"firstpara\" align=\"center\"&gt;</samp>\\n# <samp>   This is paragraph</samp>\\n# <samp>   &lt;b&gt;</samp>\\n# <samp>    one</samp>\\n# <samp>   &lt;/b&gt;</samp>\\n# <samp>   .</samp>\\n# <samp>  &lt;/p&gt;</samp>\\n# <samp>  &lt;p id=\"secondpara\" align=\"blah\"&gt;</samp>\\n# <samp>   This is paragraph</samp>\\n# <samp>   &lt;b&gt;</samp>\\n# <samp>    two</samp>\\n# <samp>   &lt;/b&gt;</samp>\\n# <samp>   .</samp>\\n# <samp>  &lt;/p&gt;</samp>\\n# <samp> &lt;/body&gt;</samp>\\n# <samp>&lt;/html&gt;</samp>\\n</pre></div>\\n\\n\\n<a name=\"The attributes of Tags\"><h3>The attributes of <code>Tag</code>s</h3></a>\\n\\n<p><code>Tag</code> and <code>NavigableString</code> objects have lots of useful members,\\nmost of which are covered in \\n\\n<a href=\"#Navigating the Parse Tree\">Navigating the Parse Tree</a> and\\n\\n<a href=\"#Searching the Parse Tree\">Searching the Parse Tree</a>.\\n\\nHowever, there\\'s one aspect of <code>Tag</code> objects we\\'ll cover here: the\\nattributes.\\n\\n<p>SGML tags have attributes:. for instance, each of the &lt;P&gt; tags in\\n<a href=\"#The document above\">the example HTML above</a> has an \"id\"\\nattribute and an \"align\" attribute. You can access a tag\\'s attributes\\nby treating the <code>Tag</code> object as though it were a dictionary:\\n\\n<div class=\"sample\"><pre>\\n<kbd>firstPTag, secondPTag = soup.findAll(\\'p\\')</kbd>\\n<kbd></kbd>\\n<kbd>firstPTag[\\'id\\']</kbd>\\n# <samp>u\\'firstPara\\'</samp>\\n<kbd></kbd>\\n<kbd>secondPTag[\\'id\\']</kbd>\\n# <samp>u\\'secondPara\\'</samp>\\n</pre></div>\\n\\n<p><code>NavigableString</code> objects don\\'t have attributes; only <code>Tag</code> objects\\nhave them.\\n\\n<a name=\"Navigating the Parse Tree\"><h2>Navigating the Parse Tree</h2></a>\\n\\n<p>All <code>Tag</code> objects have all of the members listed below (though the\\nactual value of the member may be <code>None</code>). <code>NavigableString</code> objects\\nhave all of them except for <code>contents</code> and <code>string</code>.\\n\\n<a name=\"parent\"><h3><code>parent</code></h3></a>\\n\\n<p>In <a href=\"#The document above\">the example above</a>, the parent\\nof the &lt;HEAD&gt; <code>Tag</code> is the &lt;HTML&gt; <code>Tag</code>. The parent of the &lt;HTML&gt;\\n<code>Tag</code> is the <code>BeautifulSoup</code> parser object itself. The parent of the\\nparser object is <code>None</code>. By following <code>parent</code>, you can move up the\\nparse tree:\\n\\n<div class=\"sample\"><pre>\\n<kbd>soup.head.parent.name</kbd>\\n# <samp>u\\'html\\'</samp>\\n<kbd>soup.head.parent.parent.__class__.__name__</kbd>\\n# <samp>\\'BeautifulSoup\\'</samp>\\n<kbd>soup.parent == None</kbd>\\n# <samp>True</samp>\\n</pre></div>\\n\\n<a name=\"contents\"><h3><code>contents</code></h3></a>\\n\\n<p>With <code>parent</code> you move up the parse tree. With <code>contents</code> you move\\ndown the tree. <code>contents</code> is an ordered list of the <code>Tag</code> and\\n<code>NavigableString</code> objects contained within a page element. Only the\\ntop-level parser object and <code>Tag</code> objects have\\n<code>contents</code>. <code>NavigableString</code> objects are just strings and can\\'t\\ncontain sub-elements, so they don\\'t have <code>contents</code>.\\n\\n<p>In <a href=\"#The document above\">the example above</a>, the\\n<code>contents</code> of the first &lt;P&gt; <code>Tag</code> is a list containing a\\n<code>NavigableString</code> (\"This is paragraph \"), a &lt;B&gt; <code>Tag</code>, and another\\n<code>NavigableString</code> (\".\"). The <code>contents</code> of the &lt;B&gt; <code>Tag</code>: a list\\ncontaining a <code>NavigableString</code> (\"one\").\\n\\n<div class=\"sample\"><pre>\\n<kbd>pTag = soup.p</kbd>\\n<kbd>pTag.contents</kbd>\\n# <samp>[u\\'This is paragraph \\', &lt;b&gt;one&lt;/b&gt;, u\\'.\\']</samp>\\n<kbd>pTag.contents[1].contents</kbd>\\n# <samp>[u\\'one\\']</samp>\\n<kbd>pTag.contents[0].contents</kbd>\\n# <samp>AttributeError: \\'NavigableString\\' object has no attribute \\'contents\\'</samp>\\n</pre></div>\\n\\n<a name=\"string\"><h3><code>string</code></h3></a>\\n\\n<p>For your convenience, if a tag has only one child node, and that\\nchild node is a string, the child node is made available as\\n<code>tag.string</code>, as well as <code>tag.contents[0]</code>. \\n\\nIn <a href=\"#The document above\">the example above</a>,\\n<code>soup.b.string</code> is a <code>NavigableString</code> representing the Unicode string\\n\"one\". That\\'s the string contained in the first &lt;B&gt; <code>Tag</code> in the parse\\ntree.\\n\\n<div class=\"sample\"><pre>\\n<kbd>soup.b.string</kbd>\\n# <samp>u\\'one\\'</samp>\\n<kbd>soup.b.contents[0]</kbd>\\n# <samp>u\\'one\\'</samp>\\n</pre></div>\\n\\n<p>But <code>soup.p.string</code> is <code>None</code>, because the first &lt;P&gt; <code>Tag</code> in the\\nparse tree has more than one child. <code>soup.head.string</code> is also <code>None</code>,\\neven though the &lt;HEAD&gt; Tag has only one child, because that child is a\\n<code>Tag</code> (the &lt;TITLE&gt; <code>Tag</code>), not a <code>NavigableString</code>.\\n\\n<div class=\"sample\"><pre>\\n<kbd>soup.p.string == None</kbd>\\n# <samp>True</samp>\\n<kbd>soup.head.string == None</kbd>\\n# <samp>True</samp>\\n</pre></div>\\n\\n<a name=\"nextSibling and previousSibling\"><h3><code>nextSibling</code> and <code>previousSibling</code></h3></a>\\n\\n<p>These members let you skip to the next or previous thing on the\\nsame level of the parse tree. In <a href=\"#The document above\">the\\ndocument above</a>, the <code>nextSibling</code> of the &lt;HEAD&gt; <code>Tag</code> is the\\n&lt;BODY&gt; <code>Tag</code>, because the &lt;BODY&gt; <code>Tag</code> is the next thing directly\\nbeneath the &lt;html&gt; <code>Tag</code>. The <code>nextSibling</code> of the &lt;BODY&gt; tag is\\n<code>None</code>, because there\\'s nothing else directly beneath the &lt;HTML&gt;\\n<code>Tag</code>.\\n\\n<div class=\"sample\"><pre>\\n<kbd>soup.head.nextSibling.name</kbd>\\n# <samp>u\\'body\\'</samp>\\n<kbd>soup.html.nextSibling == None</kbd>\\n# <samp>True</samp>\\n</pre></div>\\n\\n<p>Conversely, the <code>previousSibling</code> of the &lt;BODY&gt; <code>Tag</code> is the &lt;HEAD&gt;\\ntag, and the <code>previousSibling</code> of the &lt;HEAD&gt; <code>Tag</code> is <code>None</code>:\\n\\n<div class=\"sample\"><pre>\\n<kbd>soup.body.previousSibling.name</kbd>\\n# <samp>u\\'head\\'</samp>\\n<kbd>soup.head.previousSibling == None</kbd>\\n# <samp>True</samp>\\n</pre></div>\\n\\n<p>Some more examples: the <code>nextSibling</code> of the first &lt;P&gt; <code>Tag</code> is the\\nsecond &lt;P&gt; <code>Tag</code>. The <code>previousSibling</code> of the &lt;B&gt; <code>Tag</code> inside the\\nsecond &lt;P&gt; <code>Tag</code> is the <code>NavigableString</code> \"This is paragraph\". The\\n<code>previousSibling</code> of that <code>NavigableString</code> is <code>None</code>, not anything\\ninside the first &lt;P&gt; <code>Tag</code>.\\n\\n<div class=\"sample\"><pre>\\n<kbd>soup.p.nextSibling</kbd>\\n# <samp>&lt;p id=\"secondpara\" align=\"blah\"&gt;This is paragraph &lt;b&gt;two&lt;/b&gt;.&lt;/p&gt;</samp>\\n<kbd></kbd>\\n<kbd>secondBTag = soup.findAll(\\'b\\')[1]</kbd>\\n<kbd>secondBTag.previousSibling</kbd>\\n# <samp>u\\'This is paragraph\\'</samp>\\n<kbd>secondBTag.previousSibling.previousSibling == None</kbd>\\n# <samp>True</samp>\\n</pre></div>\\n\\n<a name=\"next and previous\"><h3><code>next</code> and <code>previous</code></h3></a>\\n\\n<p>These members let you move through the document elements in the\\norder they were processed by the parser, rather than in the order they\\nappear in the tree. For instance, the <code>next</code> of the &lt;HEAD&gt; <code>Tag</code> is\\nthe &lt;TITLE&gt; <code>Tag</code>, not the &lt;BODY&gt; <code>Tag</code>. This is because, in \\n\\n<a href=\"#The document above\">the original document</a>, the &lt;TITLE&gt;\\ntag comes immediately after the &lt;HEAD&gt; tag.\\n\\n<div class=\"sample\"><pre>\\n<kbd>soup.head.next</kbd>\\n# <samp>u\\'title\\'</samp>\\n<kbd>soup.head.nextSibling.name</kbd>\\n# <samp>u\\'body\\'</samp>\\n<kbd>soup.head.previous.name</kbd>\\n# <samp>u\\'html\\'</samp>\\n</pre></div>\\n\\n<p>Where <code>next</code> and <code>previous</code> are concerned, a <code>Tag</code>\\'s <code>contents</code> come\\nbefore its <code>nextSibling</code>. You usually won\\'t have to use these members,\\nbut sometimes it\\'s the easiest way to get to something buried inside\\nthe parse tree.\\n\\n<a name=\"Iterating over a Tag\"><h3>Iterating over a <code>Tag</code></h3></a>\\n\\n<p>You can iterate over the <code>contents</code> of a <code>Tag</code> by treating it as a\\nlist. This is a useful shortcut. Similarly, to see how many child\\nnodes a <code>Tag</code> has, you can call <code>len(tag)</code> instead of\\n<code>len(tag.contents)</code>. In terms of <a href=\"#The document above\">the\\ndocument above</a>:\\n\\n<div class=\"sample\"><pre>\\n<kbd>for i in soup.body:</kbd>\\n<kbd>    print i</kbd>\\n# <samp>&lt;p id=\"firstpara\" align=\"center\"&gt;This is paragraph &lt;b&gt;one&lt;/b&gt;.&lt;/p&gt;</samp>\\n# <samp>&lt;p id=\"secondpara\" align=\"blah\"&gt;This is paragraph &lt;b&gt;two&lt;/b&gt;.&lt;/p&gt;</samp>\\n<kbd></kbd>\\n<kbd>len(soup.body)</kbd>\\n# <samp>2</samp>\\n<kbd>len(soup.body.contents)</kbd>\\n# <samp>2</samp>\\n</pre></div>\\n\\n<a name=\"Using tag names as members\"><h3>Using tag names as members</h3></a>\\n\\n<p>It\\'s easy to navigate the parse tree by acting as though the name\\nof the tag you want is a member of a parser or <code>Tag</code> object. We\\'ve\\nbeen doing it throughout these examples. In terms of <a href=\"#The\\ndocument above\">the document above</a>, <code>soup.head</code> gives us the first\\n(and, as it happens, only) &lt;HEAD&gt; <code>Tag</code> in the document:\\n\\n<div class=\"sample\"><pre>\\n<kbd>soup.head</kbd>\\n# <samp>&lt;head&gt;&lt;title&gt;Page title&lt;/title&gt;&lt;/head&gt;</samp>\\n</pre></div>\\n\\n<p>In general, calling <code>mytag.foo</code> returns the first child of <code>mytag</code>\\nthat happens to be a &lt;FOO&gt; <code>Tag</code>. If there aren\\'t any &lt;FOO&gt; <code>Tag</code>s\\nbeneath <code>mytag</code>, then <code>mytag.foo</code> returns <code>None</code>.\\n\\nYou can use this to traverse the parse tree very quickly:\\n\\n<div class=\"sample\"><pre>\\n<kbd>soup.head.title</kbd>\\n# <samp>&lt;title&gt;Page title&lt;/title&gt;</samp>\\n<kbd></kbd>\\n<kbd>soup.body.p.b.string</kbd>\\n# <samp>u\\'one\\'</samp>\\n</pre></div>\\n\\n<p>You can also use this to quickly jump to a certain part of a parse\\ntree. For instance, if you\\'re not worried about &lt;TITLE&gt; tags in weird\\nplaces outside of the &lt;HEAD&gt; tag, you can just use <code>soup.title</code> to get\\nan HTML document\\'s title. You don\\'t have to use <code>soup.head.title</code>:\\n\\n<div class=\"sample\"><pre>\\n<kbd>soup.title.string</kbd>\\n# <samp>u\\'Page title\\'</samp>\\n</pre></div>\\n\\n<p><code>soup.p</code> jumps to the first &lt;P&gt; tag inside a document, wherever it\\nis. <code>soup.table.tr.td</code> jumps to the first column of the first row of\\nthe first table in the document.\\n\\n<p>These members actually alias to the <code>first</code> method, covered <a\\nhref=\"#Searching the Parse Tree\">below</a>. I mention it here because\\nthe alias makes it very easy to zoom in on an interesting part of a\\nwell-known parse tree.\\n\\n<p>An alternate form of this idiom lets you access the first &lt;FOO&gt; tag\\nas <code>.fooTag</code> instead of <code>.foo</code>. For instance, <code>soup.table.tr.td</code> could\\nalso be expressed as <code>soup.tableTag.trTag.tdTag</code>, or even\\n<code>soup.tableTag.tr.tdTag</code>. This is useful if you like to be more\\nexplicit about what you\\'re doing, or if you\\'re parsing XML whose tag\\nnames conflict with the names of Beautiful Soup methods and members.\\n\\n<div class=\"sample\"><pre>\\n<kbd>from BeautifulSoup import BeautifulStoneSoup</kbd>\\n<kbd>xml = \\'&lt;person name=\"Bob\"&gt;&lt;parent rel=\"mother\" name=\"Alice\"&gt;\\'</kbd>\\n<kbd>xmlSoup = BeautifulStoneSoup(xml)</kbd>\\n<kbd></kbd>\\n<kbd>xmlSoup.person.parent                      # A Beautiful Soup member</kbd>\\n# <samp>&lt;person name=\"Bob\"&gt;&lt;parent rel=\"mother\" name=\"Alice\"&gt;&lt;/parent&gt;&lt;/person&gt;</samp>\\n<kbd>xmlSoup.person.parentTag                   # A tag name</kbd>\\n# <samp>&lt;parent rel=\"mother\" name=\"Alice\"&gt;&lt;/parent&gt;</samp>\\n</pre></div>\\n\\n<p>If you\\'re looking for tag names that aren\\'t valid Python\\nidentifiers (like <code>hyphenated-name</code>), you need to use <code>find</code>.\\n\\n<a name=\"Searching the Parse Tree\"><h2>Searching the Parse Tree</h2></a>\\n\\n<p>Beautiful Soup provides many methods that traverse the parse tree,\\ngathering <code>Tag</code>s and <code>NavigableString</code>s that match criteria you\\nspecify.\\n\\n<p><a name=\"findall example document\">There are several ways to define\\ncriteria for matching Beautiful Soup objects. Let\\'s demonstrate by\\nexamining in depth the most basic of all Beautiful Soup search\\nmethods, <code>findAll</code>. As before, we\\'ll demonstrate on the following\\ndocument:</a>\\n\\n<div class=\"sample\"><pre>\\n<kbd>from BeautifulSoup import BeautifulSoup</kbd>\\n<kbd>doc = [\\'&lt;html&gt;&lt;head&gt;&lt;title&gt;Page title&lt;/title&gt;&lt;/head&gt;\\',</kbd>\\n<kbd>       \\'&lt;body&gt;&lt;p id=\"firstpara\" align=\"center\"&gt;This is paragraph &lt;b&gt;one&lt;/b&gt;.\\',</kbd>\\n<kbd>       \\'&lt;p id=\"secondpara\" align=\"blah\"&gt;This is paragraph &lt;b&gt;two&lt;/b&gt;.\\',</kbd>\\n<kbd>       \\'&lt;/html&gt;\\']</kbd>\\n<kbd>soup = BeautifulSoup(\\'\\'.join(doc))</kbd>\\n<kbd>print soup.prettify()</kbd>\\n# <samp>&lt;html&gt;</samp>\\n# <samp> &lt;head&gt;</samp>\\n# <samp>  &lt;title&gt;</samp>\\n# <samp>   Page title</samp>\\n# <samp>  &lt;/title&gt;</samp>\\n# <samp> &lt;/head&gt;</samp>\\n# <samp> &lt;body&gt;</samp>\\n# <samp>  &lt;p id=\"firstpara\" align=\"center\"&gt;</samp>\\n# <samp>   This is paragraph</samp>\\n# <samp>   &lt;b&gt;</samp>\\n# <samp>    one</samp>\\n# <samp>   &lt;/b&gt;</samp>\\n# <samp>   .</samp>\\n# <samp>  &lt;/p&gt;</samp>\\n# <samp>  &lt;p id=\"secondpara\" align=\"blah\"&gt;</samp>\\n# <samp>   This is paragraph</samp>\\n# <samp>   &lt;b&gt;</samp>\\n# <samp>    two</samp>\\n# <samp>   &lt;/b&gt;</samp>\\n# <samp>   .</samp>\\n# <samp>  &lt;/p&gt;</samp>\\n# <samp> &lt;/body&gt;</samp>\\n# <samp>&lt;/html&gt;</samp>\\n</pre></div>\\n\\n<p>Incidentally, the two methods described in this section (<code>findAll</code>\\nand <code>find</code>) are available only to <code>Tag</code> objects and the top-level\\nparser objects, not to <code>NavigableString</code> objects. The methods defined\\nin <a href=\"#Searching Within the Parse Tree\">Searching Within the\\nParse Tree</a> are also available to <code>NavigableString</code> objects.\\n\\n<a name=\"The basic find method: findAll(name, attrs, recursive, text, limit, **kwargs)\"><h3>The basic find method: <code>findAll(<a href=\"#arg-name\">name</a>, <a href=\"#arg-attrs\">attrs</a>, <a href=\"#arg-recursive\">recursive</a>, <a href=\"#arg-text\">text</a>, <a href=\"#arg-limit\">limit</a>, <a href=\"#arg-**kwargs\">**kwargs</a>)</code></h3></a>\\n\\n<p>The <code>findAll</code> method traverses the tree, starting at the given\\npoint, and finds all the <code>Tag</code> and <code>NavigableString</code> objects that match\\nthe criteria you give. The signature for the <code>findall</code> method is this:\\n\\n<p><b>findAll(name=None, attrs={}, recursive=True, text=None,\\nlimit=None, **kwargs)</b></p>\\n\\n<p><a name=\"args\">These arguments</a> show up\\nover and over again throughout the Beautiful Soup API. The most\\nimportant arguments are <code>name</code> and the keyword arguments.\\n\\n<ul>\\n\\n<li><p>The <a name=\"arg-name\"><b><code>name</code></b></a> argument restricts the set\\nof tags by name. There are several ways to restrict the name, and\\nthese too show up over and over again throughout the Beautiful Soup\\nAPI.\\n\\n<ol><p>\\n\\n<li><p>The simplest usage is to just pass in a tag name. This code finds\\nall the &lt;B&gt; <code>Tag</code>s in the document:\\n\\n<div class=\"sample\"><pre>\\n<kbd>soup.findAll(\\'b\\')</kbd>\\n# <samp>[&lt;b&gt;one&lt;/b&gt;, &lt;b&gt;two&lt;/b&gt;]</samp>\\n</pre></div>\\n\\n<li><p>You can also pass in a regular expression. This code finds all the\\ntags whose names <i>start</i> with B:\\n\\n<div class=\"sample\"><pre>\\n<kbd>import re</kbd>\\n<kbd>tagsStartingWithB = soup.findAll(re.compile(\\'^b\\'))</kbd>\\n<kbd>[tag.name for tag in tagsStartingWithB]</kbd>\\n# <samp>[u\\'body\\', u\\'b\\', u\\'b\\']</samp>\\n</pre></div>\\n\\n<li><p>You can pass in a list or a dictionary. These two calls find all\\nthe &lt;TITLE&gt; and all the &lt;P&gt; tags. They work the same way, but the\\nsecond call runs faster:\\n\\n<div class=\"sample\"><pre>\\n<kbd>soup.findAll([\\'title\\', \\'p\\'])</kbd>\\n# <samp>[&lt;title&gt;Page title&lt;/title&gt;, </samp>\\n# <samp> &lt;p id=\"firstpara\" align=\"center\"&gt;This is paragraph &lt;b&gt;one&lt;/b&gt;.&lt;/p&gt;, </samp>\\n# <samp> &lt;p id=\"secondpara\" align=\"blah\"&gt;This is paragraph &lt;b&gt;two&lt;/b&gt;.&lt;/p&gt;]</samp>\\n<kbd></kbd>\\n<kbd>soup.findAll({\\'title\\' : True, \\'p\\' : True})</kbd>\\n# <samp>[&lt;title&gt;Page title&lt;/title&gt;, </samp>\\n# <samp> &lt;p id=\"firstpara\" align=\"center\"&gt;This is paragraph &lt;b&gt;one&lt;/b&gt;.&lt;/p&gt;, </samp>\\n# <samp> &lt;p id=\"secondpara\" align=\"blah\"&gt;This is paragraph &lt;b&gt;two&lt;/b&gt;.&lt;/p&gt;]</samp>\\n</pre></div>\\n\\n<li><p>You can pass in the special value <code>True</code>, which matches every tag\\nwith a name: that is, it matches every tag.\\n\\n<div class=\"sample\"><pre>\\n<kbd>allTags = soup.findAll(True)</kbd>\\n<kbd>[tag.name for tag in allTags]</kbd>\\n<kbd>[u\\'html\\', u\\'head\\', u\\'title\\', u\\'body\\', u\\'p\\', u\\'b\\', u\\'p\\', u\\'b\\']</kbd>\\n</pre></div>\\n\\n<p>This doesn\\'t look useful, but <code>True</code> is very useful when\\nrestricting attribute values.\\n\\n<li><p>You can pass in a <a name=\"match-callable\">callable</a> object which\\ntakes a <code>Tag</code> object as its only argument, and returns a\\nboolean. Every <code>Tag</code> object that <code>findAll</code> encounters will be passed\\ninto this object, and if the call returns <code>True</code> then the tag is\\nconsidered to match.\\n\\n<p>This code finds the tags that have two, and only two, attributes:\\n\\n<div class=\"sample\"><pre>\\n<kbd>soup.findAll(lambda tag: len(tag.attrs) == 2)</kbd>\\n# <samp>[&lt;p id=\"firstpara\" align=\"center\"&gt;This is paragraph &lt;b&gt;one&lt;/b&gt;.&lt;/p&gt;, </samp>\\n# <samp> &lt;p id=\"secondpara\" align=\"blah\"&gt;This is paragraph &lt;b&gt;two&lt;/b&gt;.&lt;/p&gt;]</samp>\\n</pre></div>\\n\\n<p>This code finds the tags that have one-character names and no\\nattributes:\\n\\n<div class=\"sample\"><pre>\\n<kbd>soup.findAll(lambda tag: len(tag.name) == 1 and not tag.attrs)</kbd>\\n# <samp>[&lt;b&gt;one&lt;/b&gt;, &lt;b&gt;two&lt;/b&gt;]</samp>\\n</pre></div>\\n</ol>\\n\\n<li><p><a name=\"arg-**kwargs\">The keyword arguments</a> impose\\nrestrictions on the attributes of a tag. This simple example finds all\\nthe tags which have a value of \"center\" for their \"align\" attribute:\\n\\n<div class=\"sample\"><pre>\\n<kbd>soup.findAll(align=\"center\")</kbd>\\n# <samp>[&lt;p id=\"firstpara\" align=\"center\"&gt;This is paragraph &lt;b&gt;one&lt;/b&gt;.&lt;/p&gt;]</samp>\\n</pre></div>\\n\\n<p>As with the <code>name</code> argument, you can pass a keyword argument\\ndifferent kinds of object to impose different restrictions on the\\ncorresponding attribute. You can pass a string, as seen above, to\\nrestrict an attribute to a single value. You can also pass a regular\\nexpression, a list, a hash, the special values <code>True</code> or <code>None</code>, or a\\ncallable that takes the attribute value as its argument (note that the\\nvalue may be <code>None</code>). Some examples:\\n\\n<div class=\"sample\"><pre>\\n<kbd>soup.findAll(id=re.compile(\"para$\"))</kbd>\\n# <samp>[&lt;p id=\"firstpara\" align=\"center\"&gt;This is paragraph &lt;b&gt;one&lt;/b&gt;.&lt;/p&gt;,</samp>\\n# <samp> &lt;p id=\"secondpara\" align=\"blah\"&gt;This is paragraph &lt;b&gt;two&lt;/b&gt;.&lt;/p&gt;]</samp>\\n<kbd></kbd>\\n<kbd>soup.findAll(align=[\"center\", \"blah\"])</kbd>\\n# <samp>[&lt;p id=\"firstpara\" align=\"center\"&gt;This is paragraph &lt;b&gt;one&lt;/b&gt;.&lt;/p&gt;,</samp>\\n# <samp> &lt;p id=\"secondpara\" align=\"blah\"&gt;This is paragraph &lt;b&gt;two&lt;/b&gt;.&lt;/p&gt;]</samp>\\n<kbd></kbd>\\n<kbd>soup.findAll(align=lambda(value): value and len(value) &lt; 5)</kbd>\\n# <samp>[&lt;p id=\"secondpara\" align=\"blah\"&gt;This is paragraph &lt;b&gt;two&lt;/b&gt;.&lt;/p&gt;]</samp>\\n</pre></div>\\n\\n<p>The special values <code>True</code> and <code>None</code> are of special\\ninterest. <code>True</code> matches a tag that has <i>any</i> value for the given\\nattribute, and <code>None</code> matches a tag that has <i>no</i> value for the\\ngiven attribute. Some examples:\\n\\n<div class=\"sample\"><pre>\\n<kbd>soup.findAll(align=True)</kbd>\\n# <samp>[&lt;p id=\"firstpara\" align=\"center\"&gt;This is paragraph &lt;b&gt;one&lt;/b&gt;.&lt;/p&gt;,</samp>\\n# <samp> &lt;p id=\"secondpara\" align=\"blah\"&gt;This is paragraph &lt;b&gt;two&lt;/b&gt;.&lt;/p&gt;]</samp>\\n<kbd></kbd>\\n<kbd>[tag.name for tag in soup.findAll(align=None)]</kbd>\\n# <samp>[u\\'html\\', u\\'head\\', u\\'title\\', u\\'body\\', u\\'b\\', u\\'b\\']</samp>\\n</pre></div>\\n\\n<p>If you need to impose complex or interlocking restrictions on a\\ntag\\'s attributes, pass in a callable object for <code>name</code>, <a\\nhref=\"#match-callable\">as seen above</a>, and deal with the <code>Tag</code>\\nobject.\\n\\n<p><a name=\"arg-attrs\">You might have noticed a problem here.</a> What\\nif you have a document with a tag that defines an attribute called\\n<code>name</code>? You can\\'t use a keyword argument called <code>name</code> because the\\nBeautiful Soup search methods already define a <code>name</code> argument. You\\nalso can\\'t use a Python reserved word like <code>for</code> as a keyword\\nargument.\\n\\n<p>Beautiful Soup provides a special argument called <code>attrs</code> which you\\ncan use in these situations. <code>attrs</code> is a dictionary that acts just\\nlike the keyword arguments:\\n\\n<div class=\"sample\"><pre>\\n<kbd>soup.findAll(id=re.compile(\"para$\"))</kbd>\\n# <samp>[&lt;p id=\"firstpara\" align=\"center\"&gt;This is paragraph &lt;b&gt;one&lt;/b&gt;.&lt;/p&gt;,</samp>\\n# <samp> &lt;p id=\"secondpara\" align=\"blah\"&gt;This is paragraph &lt;b&gt;two&lt;/b&gt;.&lt;/p&gt;]</samp>\\n<kbd></kbd>\\n<kbd>soup.findAll(attrs={\\'id\\' : re.compile(\"para$\")})</kbd>\\n# <samp>[&lt;p id=\"firstpara\" align=\"center\"&gt;This is paragraph &lt;b&gt;one&lt;/b&gt;.&lt;/p&gt;,</samp>\\n# <samp> &lt;p id=\"secondpara\" align=\"blah\"&gt;This is paragraph &lt;b&gt;two&lt;/b&gt;.&lt;/p&gt;]</samp>\\n</pre></div>\\n\\n<p>You can use <code>attrs</code> if you need to put restrictions on attributes\\nwhose names are Python reserved words, like <code>class</code>, <code>for</code>, or\\n<code>import</code>; or attributes whose names are non-keyword arguments to the\\nBeautiful Soup search methods: <code>name</code>, <code>recursive</code>, <code>limit</code>, <code>text</code>,\\nor <code>attrs</code> itself.\\n\\n<div class=\"sample\"><pre>\\n<kbd>from BeautifulSoup import BeautifulStoneSoup</kbd>\\n<kbd>xml = \\'&lt;person name=\"Bob\"&gt;&lt;parent rel=\"mother\" name=\"Alice\"&gt;\\'</kbd>\\n<kbd>xmlSoup = BeautifulStoneSoup(xml)</kbd>\\n<kbd></kbd>\\n<kbd>xmlSoup.findAll(name=\"Alice\")</kbd>\\n# <samp>[]</samp>\\n<kbd></kbd>\\n<kbd>xmlSoup.findAll(attrs={\"name\" : \"Alice\"})</kbd>\\n# <samp>[parent rel=\"mother\" name=\"Alice\"&gt;&lt;/parent&gt;]</samp>\\n</pre></div>\\n\\n<a name=\"Searching by CSS class\"><h4>Searching by CSS class</h4></a>\\n\\n<p>The <code>attrs</code> argument would be a pretty obscure feature\\nwere it not for one thing: CSS. It\\'s very useful to search for a tag\\nthat has a certain CSS class, but the name of the CSS attribute,\\n<code>class</code>, is also a Python reserved word. \\n\\n<p>You could search by CSS class with <code>soup.find(\"tagName\", {\\n\"class\" : \"cssClass\" })</code>, but that\\'s a lot of code for such a\\ncommon operation. Instead, you can pass a string for <code>attrs</code> instead\\nof a dictionary. The string will be used to restrict the CSS class.\\n\\n<div class=\"sample\"><pre>\\n<kbd>from BeautifulSoup import BeautifulSoup</kbd>\\n<kbd>soup = BeautifulSoup(\"\"\"Bob\\'s &lt;b&gt;Bold&lt;/b&gt; Barbeque Sauce now available in </kbd>\\n<kbd>                        &lt;b class=\"hickory\"&gt;Hickory&lt;/b&gt; and &lt;b class=\"lime\"&gt;Lime&lt;/a&gt;\"\"\")</kbd>\\n<kbd></kbd>\\n<kbd>soup.find(\"b\", { \"class\" : \"lime\" })</kbd>\\n# <samp>&lt;b class=\"lime\"&gt;Lime&lt;/b&gt;</samp>\\n<kbd></kbd>\\n<kbd>soup.find(\"b\", \"hickory\")</kbd>\\n# <samp>&lt;b class=\"hickory\"&gt;Hickory&lt;/b&gt;</samp>\\n</pre></div>\\n\\n<li><p><a name=\"arg-text\"><b><code>text</code></b></a> is an argument that lets\\nyou search for <code>NavigableString</code> objects instead of <code>Tag</code>s. Its value\\ncan be a string, a regular expression, a list or dictionary, <code>True</code> or\\n<code>None</code>, or a callable that takes a <code>NavigableString</code> object as its\\nargument:\\n\\n<div class=\"sample\"><pre>\\n<kbd>soup.findAll(text=\"one\")</kbd>\\n# <samp>[u\\'one\\']</samp>\\n<kbd>soup.findAll(text=u\\'one\\')</kbd>\\n# <samp>[u\\'one\\']</samp>\\n<kbd></kbd>\\n<kbd>soup.findAll(text=[\"one\", \"two\"])</kbd>\\n# <samp>[u\\'one\\', u\\'two\\']</samp>\\n<kbd></kbd>\\n<kbd>soup.findAll(text=re.compile(\"paragraph\"))</kbd>\\n# <samp>[u\\'This is paragraph \\', u\\'This is paragraph \\']</samp>\\n<kbd></kbd>\\n<kbd>soup.findAll(text=True)</kbd>\\n# <samp>[u\\'Page title\\', u\\'This is paragraph \\', u\\'one\\', u\\'.\\', u\\'This is paragraph \\', </samp>\\n# <samp> u\\'two\\', u\\'.\\']</samp>\\n<kbd></kbd>\\n<kbd>soup.findAll(text=lambda(x): len(x) &lt; 12)</kbd>\\n# <samp>[u\\'Page title\\', u\\'one\\', u\\'.\\', u\\'two\\', u\\'.\\']</samp>\\n</pre></div>\\n\\n<p>If you use <code>text</code>, then any values you give for <code>name</code> and the\\nkeyword arguments are ignored.\\n\\n<li><p><a name=\"arg-recursive\"><b><code>recursive</code></b></a> is a boolean\\nargument (defaulting to <code>True</code>) which tells Beautiful Soup whether to\\ngo all the way down the parse tree, or whether to only look at the\\nimmediate children of the <code>Tag</code> or the parser object. Here\\'s the\\ndifference:\\n\\n<div class=\"sample\"><pre>\\n<kbd>[tag.name for tag in soup.html.findAll()]</kbd>\\n# <samp>[u\\'head\\', u\\'title\\', u\\'body\\', u\\'p\\', u\\'b\\', u\\'p\\', u\\'b\\']</samp>\\n<kbd></kbd>\\n<kbd>[tag.name for tag in soup.html.findAll(recursive=False)]</kbd>\\n# <samp>[u\\'head\\', u\\'body\\']</samp>\\n</pre></div>\\n\\n<p>When <code>recursive</code> is false, only the immediate children of the\\n&lt;HTML&gt; tag are searched. If you know that\\'s all you need to search,\\nyou can save some time this way.\\n\\n<li><p>Setting <a name=\"arg-limit\"><b><code>limit</code></b></a> argument lets you\\nstop the search once Beautiful Soup finds a certain number of matches.\\nIf there are a thousand tables in your document, but you only need the\\nfourth one, pass in 4 to <code>limit</code> and you\\'ll save time. By default,\\nthere is no limit.\\n\\n<div class=\"sample\"><pre>\\n<kbd>soup.findAll(\\'p\\', limit=1)</kbd>\\n# <samp>[&lt;p id=\"firstpara\" align=\"center\"&gt;This is paragraph &lt;b&gt;one&lt;/b&gt;.&lt;/p&gt;]</samp>\\n<kbd></kbd>\\n<kbd>soup.findAll(\\'p\\', limit=100)</kbd>\\n# <samp>[&lt;p id=\"firstpara\" align=\"center\"&gt;This is paragraph &lt;b&gt;one&lt;/b&gt;.&lt;/p&gt;, </samp>\\n# <samp> &lt;p id=\"secondpara\" align=\"blah\"&gt;This is paragraph &lt;b&gt;two&lt;/b&gt;.&lt;/p&gt;]</samp>\\n</pre></div>\\n</ul>\\n\\n<a name=\"Calling a tag is like calling findall\"><h4>Calling a tag is like calling <code>findall</code></h4></a>\\n\\n<p>A little shortcut for you. If you call the parser object or a <code>Tag</code>\\nlike a function, then you can pass in all of <code>findall</code>\\'s arguments and\\nit\\'s the same as calling <code>findall</code>. In terms of \\n\\n<a href=\"#findall example document\">the document above</a>:\\n\\n<div class=\"sample\"><pre>\\n<kbd>soup(text=lambda(x): len(x) &lt; 12)</kbd>\\n# <samp>[u\\'Page title\\', u\\'one\\', u\\'.\\', u\\'two\\', u\\'.\\']</samp>\\n<kbd></kbd>\\n<kbd>soup.body(\\'p\\', limit=1)</kbd>\\n# <samp>[&lt;p id=\"firstpara\" align=\"center\"&gt;This is paragraph &lt;b&gt;one&lt;/b&gt;.&lt;/p&gt;]</samp>\\n</pre></div>\\n\\n<a name=\"find(name, attrs, recursive, text, **kwargs)\"><h3><code>find(<a href=\"#arg-name\">name</a>, <a href=\"#arg-attrs\">attrs</a>, <a href=\"#arg-recursive\">recursive</a>, <a href=\"#arg-text\">text</a>, <a href=\"#arg-**kwargs\">**kwargs</a>)</code></h3></a>\\n\\n<p>Okay, now let\\'s look at the other search methods. They all take\\npretty much the same arguments as <code>findAll</code>.\\n\\n<p>The <code>find</code> method is almost exactly like <code>findAll</code>, except that\\ninstead of finding all the matching objects, it only finds the first\\none. It\\'s like imposing a <code>limit</code> of 1 on the result set, and then\\nextracting the single result from the array. \\n\\nIn terms of <a href=\"#findall example document\">the document above</a>:\\n\\n<div class=\"sample\"><pre>\\n<kbd>soup.findAll(\\'p\\', limit=1)</kbd>\\n# <samp>[&lt;p id=\"firstpara\" align=\"center\"&gt;This is paragraph &lt;b&gt;one&lt;/b&gt;.&lt;/p&gt;]</samp>\\n<kbd></kbd>\\n<kbd>soup.find(\\'p\\', limit=1)</kbd>\\n# <samp>&lt;p id=\"firstpara\" align=\"center\"&gt;This is paragraph &lt;b&gt;one&lt;/b&gt;.&lt;/p&gt;</samp>\\n<kbd></kbd>\\n<kbd>soup.find(\\'nosuchtag\\', limit=1) == None</kbd>\\n# <samp>True</samp>\\n</pre></div>\\n\\n<p>In general, when you see a search method with a plural name (like\\n<code>findAll</code> or <code>findNextSiblings</code>), that method takes a <code>limit</code> argument\\nand returns a list of results. When you see a search method that\\ndoesn\\'t have a plural name (like <code>find</code> or <code>findNextSibling</code>), you\\nknow that the method doesn\\'t take a <code>limit</code> and returns a single\\nresult.\\n\\n<a name=\"What happened to first?\"><h3>What happened to <code>first</code>?</h3></a>\\n\\n<p>Previous versions of Beautiful Soup had methods like <code>first</code>,\\n<code>fetch</code>, and <code>fetchPrevious</code>. These methods are sitll there, but\\nthey\\'re deprecated, and may go away soon. The total effect of all\\nthose names was very confusing. The new names are named consistently:\\nas mentioned above, if the method name is plural or refers to <code>All</code>,\\nit returns multiple objects. Otherwise, it returns one object.\\n\\n<a name=\"Searching Within the Parse Tree\"><h2>Searching Within the Parse Tree</h2></a>\\n\\n<p>The methods described above, <code>findAll</code> and <code>find</code>, start at a\\ncertain point in the parse tree and go down. They recursively iterate\\nthrough an object\\'s <code>contents</code> until they bottom out.\\n\\n<p>This means that you can\\'t call these methods on <code>NavigableString</code>\\nobjects, because they have no <code>contents</code>: they\\'re always the leaves of\\nthe parse tree.\\n\\n<p>But downwards isn\\'t the only way you can iterate through a\\ndocument. Back in <a href=\"#Navigating the Parse Tree\">Navigating the\\nParse Tree</a> I showed you many other ways: <code>parent</code>, <code>nextSibling</code>,\\nand so on. Each of these iteration techniques has two corresponding\\nmethods: one that works like <code>findAll</code>, and one that works like\\n<code>find</code>. And since <code>NavigableString</code> objects <i>do</i> support these\\noperations, you can call these methods on them as well as on <code>Tag</code>\\nobjects and the main parser object.\\n\\n<p>Why is this useful? Well, sometimes you just can\\'t use <code>findAll</code> or\\n<code>find</code> to get to the <code>Tag</code> or <code>NavigableString</code> you want. For\\ninstance, consider some HTML like this:\\n\\n<div class=\"sample\"><pre>\\n<kbd>from BeautifulSoup import BeautifulSoup</kbd>\\n<kbd>soup = BeautifulSoup(\\'\\'\\'&lt;ul&gt;</kbd>\\n<kbd> &lt;li&gt;An unrelated list</kbd>\\n<kbd>&lt;/ul&gt;</kbd>\\n<kbd></kbd>\\n<kbd>&lt;h1&gt;Heading&lt;/h1&gt;</kbd>\\n<kbd>&lt;p&gt;This is &lt;b&gt;the list you want&lt;/b&gt;:&lt;/p&gt;</kbd>\\n<kbd>&lt;ul&gt;&lt;li&gt;The data you want&lt;/ul&gt;\\'\\'\\')</kbd>\\n</pre></div>\\n\\n<p>There are a number of ways to navigate to the &lt;LI&gt; tag that contains\\nthe data you want. The most obvious is this:\\n\\n<div class=\"sample\"><pre>\\n<kbd>soup(\\'li\\', limit=2)[1]</kbd>\\n# <samp>&lt;li&gt;The data you want&lt;/li&gt;</samp>\\n</pre></div>\\n\\n<p>It should be equally obvious that that\\'s not a very stable way to get\\nthat &lt;LI&gt; tag. If you\\'re only scraping this page once it doesn\\'t\\nmatter, but if you\\'re going to scrape it many times over a long\\nperiod, such considerations become important. If the irrelevant list\\ngrows another &lt;LI&gt; tag, you\\'ll get that tag instead of the one you\\nwant, and your script will break or give the wrong data.\\n\\n<div class=\"sample\"><pre>\\n<kbd>soup(\\'ul\\', limit=2)[1].li</kbd>\\n# <samp>&lt;li&gt;The data you want&lt;/li&gt;</samp>\\n</pre></div>\\n\\n<p>That\\'s is a little better, because it can survive changes to the\\nirrelevant list. But if the document grows another irrelevant list at\\nthe top, you\\'ll get the first &lt;LI&gt; tag of that list instead of the one\\nyou want. A more reliable way of referring to the ul tag you want\\nwould better reflect that tag\\'s place in the structure of the\\ndocument.\\n\\n<p>When you look at that HTML, you might think of the list you want as\\n\\'the &lt;UL&gt; tag beneath the &lt;H1&gt; tag\\'. The problem is that the tag isn\\'t\\ncontained inside the &lt;H1&gt; tag; it just happens to comes after it. It\\'s\\neasy enough to get the &lt;H1&gt; tag, but there\\'s no way to get from there\\nto the &lt;UL&gt; tag using <code>first</code> and <code>fetch</code>, because those methods only\\nsearch the <code>contents</code> of the &lt;H1&gt; tag. You need to navigate to the\\n&lt;UL&gt; tag with the <code>next</code> or <code>nextSibling</code> members:\\n\\n<div class=\"sample\"><pre>\\n<kbd>s = soup.h1</kbd>\\n<kbd>while getattr(s, \\'name\\', None) != \\'ul\\':</kbd>\\n<kbd>    s = s.nextSibling</kbd>\\n<kbd>s.li</kbd>\\n# <samp>&lt;li&gt;The data you want&lt;/li&gt;</samp>\\n</pre></div>\\n\\n<p>Or, if you think this might be more stable:\\n\\n<div class=\"sample\"><pre>\\n<kbd>s = soup.find(text=\\'Heading\\')</kbd>\\n<kbd>while getattr(s, \\'name\\', None) != \\'ul\\':</kbd>\\n<kbd>    s = s.next</kbd>\\n<kbd>s.li</kbd>\\n# <samp>&lt;li&gt;The data you want&lt;/li&gt;</samp>\\n</pre></div>\\n\\n<p>But that\\'s more trouble than you should need to go through. The\\nmethods in this section provide a useful shorthand. They can be used\\nwhenever you find yourself wanting to write a while loop over one of\\nthe navigation members. Given a starting point somewhere in the tree,\\nthey navigate the tree in some way and keep track of <code>Tag</code> or\\n<code>NavigableString</code> objects that match the criteria you specify. Instead of\\nthe first loop in the example code above, you can just write this:\\n\\n<div class=\"sample\"><pre>\\n<kbd>soup.h1.findNextSibling(\\'ul\\').li</kbd>\\n# <samp>&lt;li&gt;The data you want&lt;/li&gt;</samp>\\n</pre></div>\\n\\n<p>Instead of the second loop, you can write this:\\n\\n<div class=\"sample\"><pre>\\n<kbd>soup.find(text=\\'Heading\\').findNext(\\'ul\\').li</kbd>\\n# <samp>&lt;li&gt;The data you want&lt;/li&gt;</samp>\\n</pre></div>\\n\\n<p>The loops are replaced with calls to <code>findNextSibling</code> and\\n<code>findNext</code>. The rest of this section is a reference to all the methods\\nof this kind. Again, there are two methods for every navigation\\nmember: one that returns a list the way <code>findAll</code> does, and one that\\nreturns a scalar the way <code>find</code> does.\\n\\n<p><a name=\"Search example document\">One last time, let\\'s load up\\nthe familiar soup document for example\\'s sake:</a>\\n\\n<div class=\"sample\"><pre>\\n<kbd>from BeautifulSoup import BeautifulSoup</kbd>\\n<kbd>doc = [\\'&lt;html&gt;&lt;head&gt;&lt;title&gt;Page title&lt;/title&gt;&lt;/head&gt;\\',</kbd>\\n<kbd>       \\'&lt;body&gt;&lt;p id=\"firstpara\" align=\"center\"&gt;This is paragraph &lt;b&gt;one&lt;/b&gt;.\\',</kbd>\\n<kbd>       \\'&lt;p id=\"secondpara\" align=\"blah\"&gt;This is paragraph &lt;b&gt;two&lt;/b&gt;.\\',</kbd>\\n<kbd>       \\'&lt;/html&gt;\\']</kbd>\\n<kbd>soup = BeautifulSoup(\\'\\'.join(doc))</kbd>\\n<kbd>print soup.prettify()</kbd>\\n# <samp>&lt;html&gt;</samp>\\n# <samp> &lt;head&gt;</samp>\\n# <samp>  &lt;title&gt;</samp>\\n# <samp>   Page title</samp>\\n# <samp>  &lt;/title&gt;</samp>\\n# <samp> &lt;/head&gt;</samp>\\n# <samp> &lt;body&gt;</samp>\\n# <samp>  &lt;p id=\"firstpara\" align=\"center\"&gt;</samp>\\n# <samp>   This is paragraph</samp>\\n# <samp>   &lt;b&gt;</samp>\\n# <samp>    one</samp>\\n# <samp>   &lt;/b&gt;</samp>\\n# <samp>   .</samp>\\n# <samp>  &lt;/p&gt;</samp>\\n# <samp>  &lt;p id=\"secondpara\" align=\"blah\"&gt;</samp>\\n# <samp>   This is paragraph</samp>\\n# <samp>   &lt;b&gt;</samp>\\n# <samp>    two</samp>\\n# <samp>   &lt;/b&gt;</samp>\\n# <samp>   .</samp>\\n# <samp>  &lt;/p&gt;</samp>\\n# <samp> &lt;/body&gt;</samp>\\n# <samp>&lt;/html&gt;</samp>\\n</pre></div>\\n\\n<a name=\"findNextSiblings(name, attrs, text, limit, **kwargs) and findNextSibling(name, attrs, text, **kwargs)\"><h3><code>findNextSiblings(<a href=\"#arg-name\">name</a>, <a href=\"#arg-attrs\">attrs</a>, <a href=\"#arg-text\">text</a>, <a href=\"#arg-limit\">limit</a>, <a href=\"#arg-**kwargs\">**kwargs</a>)</code> and <code>findNextSibling(<a href=\"#arg-name\">name</a>, <a href=\"#arg-attrs\">attrs</a>, <a href=\"#arg-text\">text</a>, <a href=\"#arg-**kwargs\">**kwargs</a>)</code></h3></a>\\n\\n<p>These methods repeatedly follow an object\\'s <code>nextSibling</code> member,\\ngathering <code>Tag</code> or <code>NavigableText</code> objects that match the criteria you\\nspecify. In terms of <a href=\"#Search example document\">the document\\nabove</a>:\\n\\n<div class=\"sample\"><pre>\\n<kbd>paraText = soup.find(text=\\'This is paragraph \\')</kbd>\\n<kbd>paraText.findNextSiblings(\\'b\\')</kbd>\\n# <samp>[&lt;b&gt;one&lt;/b&gt;]</samp>\\n<kbd></kbd>\\n<kbd>paraText.findNextSibling(text = lambda(text): len(text) == 1)</kbd>\\n# <samp>u\\'.\\'</samp>\\n</pre></div>\\n\\n<a name=\"findPreviousSiblings(name, attrs, text, limit, **kwargs) and findPreviousSibling(name, attrs, text, **kwargs)\"><h3><code>findPreviousSiblings(<a href=\"#arg-name\">name</a>, <a href=\"#arg-attrs\">attrs</a>, <a href=\"#arg-text\">text</a>, <a href=\"#arg-limit\">limit</a>, <a href=\"#arg-**kwargs\">**kwargs</a>)</code> and <code>findPreviousSibling(<a href=\"#arg-name\">name</a>, <a href=\"#arg-attrs\">attrs</a>, <a href=\"#arg-text\">text</a>, <a href=\"#arg-**kwargs\">**kwargs</a>)</code></h3></a>\\n\\n<p>These methods repeatedly follow an object\\'s <code>previousSibling</code> member,\\ngathering <code>Tag</code> or <code>NavigableText</code> objects that match the criteria you\\nspecify. In terms of <a href=\"#Search example document\">the document\\nabove</a>:\\n\\n<div class=\"sample\"><pre>\\n<kbd>paraText = soup.find(text=\\'.\\')</kbd>\\n<kbd>paraText.findPreviousSiblings(\\'b\\')</kbd>\\n# <samp>[&lt;b&gt;one&lt;/b&gt;]</samp>\\n<kbd></kbd>\\n<kbd>paraText.findPreviousSibling(text = True)</kbd>\\n# <samp>u\\'This is paragraph \\'</samp>\\n</pre></div>\\n\\n<a name=\"findAllNext(name, attrs, text, limit, **kwargs) and findNext(name, attrs, text, **kwargs)\"><h3><code>findAllNext(<a href=\"#arg-name\">name</a>, <a href=\"#arg-attrs\">attrs</a>, <a href=\"#arg-text\">text</a>, <a href=\"#arg-limit\">limit</a>, <a href=\"#arg-**kwargs\">**kwargs</a>)</code> and <code>findNext(<a href=\"#arg-name\">name</a>, <a href=\"#arg-attrs\">attrs</a>, <a href=\"#arg-text\">text</a>, <a href=\"#arg-**kwargs\">**kwargs</a>)</code></h3></a>\\n\\n<p>These methods repeatedly follow an object\\'s <code>next</code> member,\\ngathering <code>Tag</code> or <code>NavigableText</code> objects that match the criteria you\\nspecify. In terms of <a href=\"#Search example document\">the document\\nabove</a>:\\n\\n<div class=\"sample\"><pre>\\n<kbd>pTag = soup.find(\\'p\\')</kbd>\\n<kbd>pTag.findAllNext(text=True)</kbd>\\n# <samp>[u\\'This is paragraph \\', u\\'one\\', u\\'.\\', u\\'This is paragraph \\', u\\'two\\', u\\'.\\']</samp>\\n<kbd></kbd>\\n<kbd>pTag.findNext(\\'p\\')</kbd>\\n# <samp>&lt;p id=\"secondpara\" align=\"blah\"&gt;This is paragraph &lt;b&gt;two&lt;/b&gt;.&lt;/p&gt;</samp>\\n<kbd></kbd>\\n<kbd>pTag.findNext(\\'b\\')</kbd>\\n# <samp>&lt;b&gt;one&lt;/b&gt;</samp>\\n</pre></div>\\n\\n<a name=\"findAllPrevious(name, attrs, text, limit, **kwargs) and findPrevious(name, attrs, text, **kwargs)\"><h3><code>findAllPrevious(<a href=\"#arg-name\">name</a>, <a href=\"#arg-attrs\">attrs</a>, <a href=\"#arg-text\">text</a>, <a href=\"#arg-limit\">limit</a>, <a href=\"#arg-**kwargs\">**kwargs</a>)</code> and <code>findPrevious(<a href=\"#arg-name\">name</a>, <a href=\"#arg-attrs\">attrs</a>, <a href=\"#arg-text\">text</a>, <a href=\"#arg-**kwargs\">**kwargs</a>)</code></h3></a>\\n\\n<p>These methods repeatedly follow an object\\'s <code>previous</code> member,\\ngathering <code>Tag</code> or <code>NavigableText</code> objects that match the criteria you\\nspecify. In terms of <a href=\"#Search example document\">the document\\nabove</a>:\\n\\n<div class=\"sample\"><pre>\\n<kbd>lastPTag = soup(\\'p\\')[-1]</kbd>\\n<kbd>lastPTag.findAllPrevious(text=True)</kbd>\\n# <samp>[u\\'.\\', u\\'one\\', u\\'This is paragraph \\', u\\'Page title\\']</samp>\\n# <samp>Note the reverse order!</samp>\\n<kbd></kbd>\\n<kbd>lastPTag.findPrevious(\\'p\\')</kbd>\\n# <samp>&lt;p id=\"firstpara\" align=\"center\"&gt;This is paragraph &lt;b&gt;one&lt;/b&gt;.&lt;/p&gt;</samp>\\n<kbd></kbd>\\n<kbd>lastPTag.findPrevious(\\'b\\')</kbd>\\n# <samp>&lt;b&gt;one&lt;/b&gt;</samp>\\n</pre></div>\\n\\n<h3><code>findParents(<a href=\"#arg-name\">name</a>, <a href=\"#arg-attrs\">attrs</a>, <a href=\"#arg-limit\">limit</a>, <a href=\"#arg-**kwargs\">**kwargs</a>)</code> and\\n<code>findParent(<a href=\"#arg-name\">name</a>, <a href=\"#arg-attrs\">attrs</a>, <a href=\"#arg-**kwargs\">**kwargs</a>)</code></h3>\\n\\n<p>These methods repeatedly follow an object\\'s <code>parent</code> member,\\ngathering <code>Tag</code> or <code>NavigableText</code> objects that match the criteria you\\nspecify. They don\\'t take a <code>text</code> argument, because there\\'s no way any\\nobject can have a <code>NavigableString</code> for a parent. In terms of <a\\nhref=\"#Search example document\">the document above</a>:\\n\\n<div class=\"sample\"><pre>\\n<kbd>bTag = soup.find(\\'b\\')</kbd>\\n<kbd></kbd>\\n<kbd>[tag.name for tag in bTag.findParents()]</kbd>\\n# <samp>[u\\'p\\', u\\'body\\', u\\'html\\', \\'[document]\\']</samp>\\n# <samp>NOTE: \"u\\'[document]\\'\" means that that the parser object itself matched.</samp>\\n<kbd></kbd>\\n<kbd>bTag.findParent(\\'body\\').name</kbd>\\n# <samp>u\\'body\\'</samp>\\n</pre></div>\\n\\n<a name=\"Modifying the Parse Tree\"><h2>Modifying the Parse Tree</h2></a>\\n\\n<p>Now you know how to find things in the parse tree. But maybe you\\nwant to modify it and print it back out. You can just rip an element\\nout of its parent\\'s <code>contents</code>, but the rest of the document will\\nstill have references to the thing you ripped out. Beautiful Soup\\noffers several methods that let you modify the parse tree while\\nmaintaining its internal consistency.\\n\\n<a name=\"Changing attribute values\"><h3>Changing attribute values</h3></a>\\n\\n<p>You can use dictionary assignment to modify the attribute values of\\n<code>Tag</code> objects. \\n\\n<div class=\"sample\"><pre>\\n<kbd>from BeautifulSoup import BeautifulSoup</kbd>\\n<kbd>soup = BeautifulSoup(\"&lt;b id=\"2\"&gt;Argh!&lt;/b&gt;\")</kbd>\\n<kbd>print soup</kbd>\\n# <samp>&lt;b id=\"2\"&gt;Argh!&lt;/b&gt;</samp>\\n<kbd>b = soup.b</kbd>\\n<kbd></kbd>\\n<kbd>b[\\'id\\'] = 10</kbd>\\n<kbd>print soup</kbd>\\n# <samp>&lt;b id=\"10\"&gt;Argh!&lt;/b&gt;</samp>\\n<kbd></kbd>\\n<kbd>b[\\'id\\'] = \"ten\"</kbd>\\n<kbd>print soup</kbd>\\n# <samp>&lt;b id=\"ten\"&gt;Argh!&lt;/b&gt;</samp>\\n<kbd></kbd>\\n<kbd>b[\\'id\\'] = \\'one \"million\"\\'</kbd>\\n<kbd>print soup</kbd>\\n# <samp>&lt;b id=\\'one \"million\"\\'&gt;Argh!&lt;/b&gt;</samp>\\n</pre></div>\\n\\n<p>You can also delete attribute values, and add new ones:</p>\\n\\n<div class=\"sample\"><pre>\\n<kbd>del(b[\\'id\\'])</kbd>\\n<kbd>print soup</kbd>\\n# <samp>&lt;b&gt;Argh!&lt;/b&gt;</samp>\\n<kbd></kbd>\\n<kbd>b[\\'class\\'] = \"extra bold and brassy!\"</kbd>\\n<kbd>print soup</kbd>\\n# <samp>&lt;b class=\"extra bold and brassy!\"&gt;Argh!&lt;/b&gt;</samp>\\n</pre></div>\\n\\n<a name=\"Removing elements\"><h3>Removing elements</h3></a>\\n\\n<p>Once you have a reference to an element, you can rip it out of the\\ntree with the <code>extract</code> method. This code removes all the comments\\nfrom a document:\\n\\n<div class=\"sample\"><pre>\\n<kbd>from BeautifulSoup import BeautifulSoup, Comment</kbd>\\n<kbd>soup = BeautifulSoup(\"\"\"1&lt;!--The loneliest number--&gt;</kbd>\\n<kbd>                        &lt;a&gt;2&lt;!--Can be as bad as one--&gt;&lt;b&gt;3\"\"\")</kbd>\\n<kbd>comments = soup.findAll(text=lambda text:isinstance(text, Comment))</kbd>\\n<kbd>[comment.extract() for comment in comments]</kbd>\\n<kbd>print soup</kbd>\\n# <samp>1</samp>\\n# <samp>&lt;a&gt;2&lt;b&gt;3&lt;/b&gt;&lt;/a&gt;</samp>\\n</pre></div>\\n\\n<p>This code removes a whole subtree from a document:\\n\\n<div class=\"sample\"><pre>\\n<kbd>from BeautifulSoup import BeautifulSoup</kbd>\\n<kbd>soup = BeautifulSoup(\"&lt;a1&gt;&lt;/a1&gt;&lt;a&gt;&lt;b&gt;Amazing content&lt;c&gt;&lt;d&gt;&lt;/a&gt;&lt;a2&gt;&lt;/a2&gt;\")</kbd>\\n<kbd>soup.a1.nextSibling</kbd>\\n# <samp>&lt;a&gt;&lt;b&gt;Amazing content&lt;c&gt;&lt;d&gt;&lt;/d&gt;&lt;/c&gt;&lt;/b&gt;&lt;/a&gt;</samp>\\n<kbd>soup.a2.previousSibling</kbd>\\n# <samp>&lt;a&gt;&lt;b&gt;Amazing content&lt;c&gt;&lt;d&gt;&lt;/d&gt;&lt;/c&gt;&lt;/b&gt;&lt;/a&gt;</samp>\\n<kbd></kbd>\\n<kbd>subtree = soup.a</kbd>\\n<kbd>subtree.extract()</kbd>\\n<kbd></kbd>\\n<kbd>print soup</kbd>\\n# <samp>&lt;a1&gt;&lt;/a1&gt;&lt;a2&gt;&lt;/a2&gt;</samp>\\n<kbd>soup.a1.nextSibling</kbd>\\n# <samp>&lt;a2&gt;&lt;/a2&gt;</samp>\\n<kbd>soup.a2.previousSibling</kbd>\\n# <samp>&lt;a1&gt;&lt;/a1&gt;</samp>\\n</pre></div>\\n\\n<p>The <code>extract</code> method turns one parse tree into two disjoint\\ntrees. The navigation members are changed so that it looks like the\\ntrees had never been together:\\n\\n<div class=\"sample\"><pre>\\n<kbd>soup.a1.nextSibling</kbd>\\n# <samp>&lt;a2&gt;&lt;/a2&gt;</samp>\\n<kbd>soup.a2.previousSibling</kbd>\\n# <samp>&lt;a1&gt;&lt;/a1&gt;</samp>\\n<kbd>subtree.previousSibling == None</kbd>\\n# <samp>True</samp>\\n<kbd>subtree.parent == None</kbd>\\n# <samp>True</samp>\\n</pre></div>\\n\\n<a name=\"Replacing one Element with Another\"><h3>Replacing one Element with Another</h3></a>\\n\\n<p>The <code>replaceWith</code> method extracts one page element and replaces it\\nwith a different one. The new element can be a <code>Tag</code> (possibly with a\\nwhole parse tree beneath it) or a <code>NavigableString</code>. If you pass a\\nplain old string into <code>replaceWith</code>, it gets turned into a\\n<code>NavigableString</code>. The navigation members are changed as though the\\ndocument had been parsed that way in the first place.\\n\\n<p>Here\\'s a simple example:\\n\\n<div class=\"sample\"><pre>\\n<kbd>from BeautifulSoup import BeautifulSoup</kbd>\\n<kbd>soup = BeautifulSoup(\"&lt;b&gt;Argh!&lt;/b&gt;\")</kbd>\\n<kbd>soup.find(text=\"Argh!\").replaceWith(\"Hooray!\")</kbd>\\n<kbd>print soup</kbd>\\n# <samp>&lt;b&gt;Hooray!&lt;/b&gt;</samp>\\n<kbd></kbd>\\n<kbd>newText = soup.find(text=\"Hooray!\")</kbd>\\n<kbd>newText.previous</kbd>\\n# <samp>&lt;b&gt;Hooray!&lt;/b&gt;</samp>\\n<kbd>newText.previous.next</kbd>\\n# <samp>u\\'Hooray!\\'</samp>\\n<kbd>newText.parent</kbd>\\n# <samp>&lt;b&gt;Hooray!&lt;/b&gt;</samp>\\n<kbd>soup.b.contents</kbd>\\n# <samp>[u\\'Hooray!\\']</samp>\\n</pre></div>\\n\\n<p>Here\\'s a more complex example that replaces one tag with another:\\n\\n<div class=\"sample\"><pre>\\n<kbd>from BeautifulSoup import BeautifulSoup, Tag</kbd>\\n<kbd>soup = BeautifulSoup(\"&lt;b&gt;Argh!&lt;a&gt;Foo&lt;/a&gt;&lt;/b&gt;&lt;i&gt;Blah!&lt;/i&gt;\")</kbd>\\n<kbd>tag = Tag(soup, \"newTag\", [(\"id\", 1)])</kbd>\\n<kbd>tag.insert(0, \"Hooray!\")</kbd>\\n<kbd>soup.a.replaceWith(tag)</kbd>\\n<kbd>print soup</kbd>\\n# <samp>&lt;b&gt;Argh!&lt;newTag id=\"1\"&gt;Hooray!&lt;/newTag&gt;&lt;/b&gt;&lt;i&gt;Blah!&lt;/i&gt;</samp>\\n</pre></div>\\n\\n<p>You can even rip out an element from one part of the document and\\nstick it in another part:\\n\\n<div class=\"sample\"><pre>\\n<kbd>from BeautifulSoup import BeautifulSoup</kbd>\\n<kbd>text = \"&lt;html&gt;There\\'s &lt;b&gt;no&lt;/b&gt; business like &lt;b&gt;show&lt;/b&gt; business&lt;/html&gt;\"</kbd>\\n<kbd>soup = BeautifulSoup(text)</kbd>\\n<kbd></kbd>\\n<kbd>no, show = soup.findAll(\\'b\\')</kbd>\\n<kbd>show.replaceWith(no)</kbd>\\n<kbd>print soup</kbd>\\n# <samp>&lt;html&gt;There\\'s  business like &lt;b&gt;no&lt;/b&gt; business&lt;/html&gt;</samp>\\n</pre></div>\\n\\n<a name=\"Adding a Brand New Element\"><h3>Adding a Brand New Element</h3></a>\\n\\n<p>The <code>Tag</code> class and the parser classes support a method called\\n<code>insert</code>. It works just like a Python list\\'s <code>insert</code> method: it takes\\nan index to the tag\\'s <code>contents</code> member, and sticks a new element in\\nthat slot.\\n\\n<p>This was demonstrated in the previous section, when we replaced a\\ntag in the document with a brand new tag. You can use <code>insert</code> to\\nbuild up an entire parse tree from scratch:\\n\\n<div class=\"sample\"><pre>\\n<kbd>from BeautifulSoup import BeautifulSoup, Tag, NavigableString</kbd>\\n<kbd>soup = BeautifulSoup()</kbd>\\n<kbd>tag1 = Tag(soup, \"mytag\")</kbd>\\n<kbd>tag2 = Tag(soup, \"myOtherTag\")</kbd>\\n<kbd>tag3 = Tag(soup, \"myThirdTag\")</kbd>\\n<kbd>soup.insert(0, tag1)</kbd>\\n<kbd>tag1.insert(0, tag2)</kbd>\\n<kbd>tag1.insert(1, tag3)</kbd>\\n<kbd>print soup</kbd>\\n# <samp>&lt;mytag&gt;&lt;myOtherTag&gt;&lt;/myOtherTag&gt;&lt;myThirdTag&gt;&lt;/myThirdTag&gt;&lt;/mytag&gt;</samp>\\n<kbd></kbd>\\n<kbd>text = NavigableString(\"Hello!\")</kbd>\\n<kbd>tag3.insert(0, text)</kbd>\\n<kbd>print soup</kbd>\\n# <samp>&lt;mytag&gt;&lt;myOtherTag&gt;&lt;/myOtherTag&gt;&lt;myThirdTag&gt;Hello!&lt;/myThirdTag&gt;&lt;/mytag&gt;</samp>\\n</pre></div>\\n\\n<p>An element can occur in only one place in one parse tree. If you\\ngive <code>insert</code> an element that\\'s already connected to a soup object, it\\ngets disconnected (with <code>extract</code>) before it gets connected\\nelsewhere. In this example, I try to insert my <code>NavigableString</code> into\\na second part of the soup, but it doesn\\'t get inserted again. It gets\\nmoved:\\n\\n<div class=\"sample\"><pre>\\n<kbd>tag2.insert(0, text)</kbd>\\n<kbd>print soup</kbd>\\n# <samp>&lt;mytag&gt;&lt;myOtherTag&gt;Hello!&lt;/myOtherTag&gt;&lt;myThirdTag&gt;&lt;/myThirdTag&gt;&lt;/mytag&gt;</samp>\\n</pre></div>\\n\\n<p>This happens even if the element previously belonged to a\\ncompletely different soup object. An element can only have one\\n<code>parent</code>, one <code>nextSibling</code>, et cetera, so it can only be in one place\\nat a time.\\n\\n<a name=\"Troubleshooting\"><h2>Troubleshooting</h2></a>\\n\\n<p>This section covers common problems people have with Beautiful Soup.\\n\\n<a name=\"Why can\\'t Beautiful Soup print out the non-ASCII characters I gave it?\"><h3>Why can\\'t Beautiful Soup print out the non-ASCII characters I gave it?</h3></a>\\n\\n<p>If you\\'re getting errors that say: \\n<code>\"\\'ascii\\' codec can\\'t encode character \\'x\\' in position y: ordinal not in range(128)\"</code>, \\nthe problem is probably with your Python installation rather than with\\nBeautiful Soup. Try printing out the non-ASCII characters without\\nrunning them through Beautiful Soup and you should have the same\\nproblem. For instance, try running code like this:\\n\\n<div class=\"sample\"><pre>\\n<kbd>latin1word = \\'Sacr\\\\xe9 bleu!\\'</kbd>\\n<kbd>unicodeword = unicode(latin1word, \\'latin-1\\')</kbd>\\n<kbd>print unicodeword</kbd>\\n</pre></div>\\n\\n<p>If this works but Beautiful Soup doesn\\'t, there\\'s probably a bug in\\nBeautiful Soup. However, if this doesn\\'t work, the problem\\'s with your\\nPython setup. Python is playing it safe and not sending non-ASCII\\ncharacters to your terminal. There are two ways to override this\\nbehavior.\\n\\n<ol>\\n<li>\\n\\n<p>The easy way is to remap standard output to a converter that\\'s\\nnot afraid to send ISO-Latin-1 or UTF-8 characters to the terminal.\\n\\n<div class=\"sample\"><pre>\\n<kbd>import codecs</kbd>\\n<kbd>import sys</kbd>\\n<kbd>streamWriter = codecs.lookup(\\'utf-8\\')[-1]</kbd>\\n<kbd>sys.stdout = streamWriter(sys.stdout)</kbd>\\n</pre></div>\\n\\n<p><code>codecs.lookup</code> returns a number of bound methods and\\nother objects related to a codec. The last one is a\\n<code>StreamWriter</code> object capable of wrapping an output\\nstream.</p>\\n\\n<li><p>The hard way is to create a <code>sitecustomize.py</code> file\\nin your Python installation which sets the default encoding to\\nISO-Latin-1 or to UTF-8. Then all your Python programs will use that\\nencoding for standard output, without you having to do something for\\neach program. In my installation, I have a\\n<code>/usr/lib/python/sitecustomize.py</code> which looks like this:\\n\\n<div class=\"sample\"><pre>\\n<kbd>import sys</kbd>\\n<kbd>sys.setdefaultencoding(\"utf-8\")</kbd>\\n</pre></div>\\n</ol>\\n\\n<p>For more information about Python\\'s Unicode support, look at <a\\nhref=\"http://dalchemy.com/opensource/unicodedoc/\">Unicode for\\nProgrammers</a> or <a\\nhref=\"http://dalchemy.com/opensource/unicodedoc/\">End to End Unicode\\nWeb Applications in Python</a>. Recipes 1.20 and 1.21 in the Python\\ncookbook are also very helpful.\\n\\n<p>Remember, even if your terminal display is restricted to ASCII, you\\ncan still use Beautiful Soup to parse, process, and write documents in\\nUTF-8 and other encodings. You just can\\'t print certain strings with\\n<code>print</code>.\\n\\n<a name=\"Beautiful Soup loses the data I fed it! Why? WHY?????\"><h3>Beautiful Soup loses the data I fed it! Why? WHY?????</h3></a>\\n\\n<p>Beautiful Soup can handle poorly-structured SGML, but sometimes\\nit loses data when it gets stuff that\\'s not SGML at all. This is\\nnot nearly as common as poorly-structured markup, but if you\\'re\\nbuilding a web crawler or something you\\'ll surely run into it.\\n\\n<p>The only solution is to \\n\\n<a href=\"#Sanitizing Bad Data with Regexps\">sanitize the data ahead of\\ntime</a> with a regular expression. Here are some examples that I and\\nBeautiful Soup users have discovered:\\n\\n<ul> \\n\\n<li><p>Beautiful Soup treats ill-formed XML definitions as data. However,\\nit loses well-formed XML definitions that don\\'t actually exist:\\n\\n<div class=\"sample\"><pre>\\n<kbd>from BeautifulSoup import BeautifulSoup</kbd>\\n<kbd>BeautifulSoup(\"&lt; ! FOO @=&gt;\")</kbd>\\n# <samp>&lt; ! FOO @=&gt;</samp>\\n<kbd>BeautifulSoup(\"&lt;b&gt;&lt;!FOO&gt;!&lt;/b&gt;\")</kbd>\\n# <samp>&lt;b&gt;!&lt;/b&gt;</samp>\\n</pre></div>\\n\\n<li><p>If your document starts a declaration and never finishes it,\\nBeautiful Soup assumes the rest of your document is part of the\\ndeclaration. If the document ends in the middle of the declaration,\\nBeautiful Soup ignores the declaration totally. A couple examples:\\n\\n<div class=\"sample\"><pre>\\n<kbd>from BeautifulSoup import BeautifulSoup</kbd>\\n<kbd></kbd>\\n<kbd>BeautifulSoup(\"foo&lt;!bar\") </kbd>\\n# <samp>foo </samp>\\n<kbd></kbd>\\n<kbd>soup = BeautifulSoup(\"&lt;html&gt;foo&lt;!bar&lt;/html&gt;\") </kbd>\\n<kbd>print soup.prettify()</kbd>\\n# <samp>&lt;html&gt;</samp>\\n# <samp> foo&lt;!bar&lt;/html&gt;</samp>\\n# <samp>&lt;/html&gt;</samp>\\n</pre></div>\\n\\n<p>There are a couple ways to fix this; one is detailed <a\\nhref=\"http://groups.google.com/group/beautifulsoup/browse_thread/thread/69093cb0d3a3cf63\">here</a>.\\n\\n<p>Beautiful Soup also ignores an entity reference that\\'s not finished\\nby the end of the document:\\n\\n<div class=\"sample\"><pre>\\n<kbd>BeautifulSoup(\"&amp;lt;foo&amp;gt\")</kbd>\\n# <samp>&amp;lt;foo</samp>\\n</pre></div>\\n\\n<p>I\\'ve never seen this in real web pages, but it\\'s probably out there\\nsomewhere.\\n\\n<li><p>A malformed comment will make Beautiful Soup ignore the rest of\\nthe document. This is covered as the example in <a href=\"#Sanitizing \\nBad Data with Regexps\">Sanitizing Bad Data with Regexps</a>.\\n\\n</ul>\\n\\n<h3>The parse tree built by the <code>BeautifulSoup</code> class offends my\\nsenses!</h3>\\n\\n<p>To get your markup parsed differently, check out \\n\\n<a href=\"#Other Built-In Parsers\">Other Built-In Parsers</a>, or else\\n<a href=\"#Customizing the Parser\">build a custom parser</a>.\\n\\n<a name=\"Beautiful Soup is too slow!\"><h3>Beautiful Soup is too slow!</h3></a>\\n\\n<p>Beautiful Soup will never run as fast as ElementTree or a\\ncustom-built <code>SGMLParser</code> subclass. ElementTree is written in C, and\\n<code>SGMLParser</code> lets you write your own mini-Beautiful Soup that only\\ndoes what you want. The point of Beautiful Soup is to save programmer\\ntime, not processor time.\\n\\n<p>That said, you can speed up Beautiful Soup quite a lot by <a\\n\\nhref=\"#Improving Performance by Parsing Only Part of the Document\">only \\n\\nparsing the parts of the document you need</a>, and you\\ncan make unneeded objects get garbage-collected by using <a\\nhref=\"#Improving Memory Usage with extract\"><code>extract</code> or <code>decompose</code></a>.\\n\\n<a name=\"Advanced Topics\"><h2>Advanced Topics</h2></a>\\n\\n<p>That does it for the basic usage of Beautiful Soup. But HTML and\\nXML are tricky, and in the real world they\\'re even trickier. So\\nBeautiful Soup keeps some extra tricks of its own up its sleeve.\\n\\n<a name=\"Generators\"><h3>Generators</h3></a>\\n\\n<p>The search methods described above are driven by generator\\nmethods. You can use these methods yourself: they\\'re called\\n<code>nextGenerator</code>, <code>previousGenerator</code>, <code>nextSiblingGenerator</code>,\\n<code>previousSiblingGenerator</code>, and <code>parentGenerator</code>. <code>Tag</code> and parser\\nobjects also have <code>childGenerator</code> and <code>recursiveChildGenerator</code>\\navailable. \\n\\n<p>Here\\'s a simple example that strips HTML tags out of a document by\\niterating over the document and collecting all the strings.\\n\\n<div class=\"sample\"><pre>\\n<kbd>from BeautifulSoup import BeautifulSoup</kbd>\\n<kbd>soup = BeautifulSoup(\"\"\"&lt;div&gt;You &lt;i&gt;bet&lt;/i&gt;</kbd>\\n<kbd>&lt;a href=\"http://www.crummy.com/software/BeautifulSoup/\"&gt;BeautifulSoup&lt;/a&gt;</kbd>\\n<kbd>rocks!&lt;/div&gt;\"\"\")</kbd>\\n<kbd></kbd>\\n<kbd>\\'\\'.join([e for e in soup.recursiveChildGenerator() </kbd>\\n<kbd>         if isinstance(e,unicode)])</kbd>\\n# <samp>u\\'You bet\\\\nBeautifulSoup\\\\nrocks!\\'</samp>\\n</pre></div>\\n\\n<p>Of course, you don\\'t really need a generator to find only the text\\nbeneath a tag. That code does the same thing as <code>.findAll(text=True)</code>.\\n\\n<div class=\"sample\"><pre>\\n<kbd>\\'\\'.join(soup.findAll(text=True))</kbd>\\n# <samp>u\\'You bet\\\\nBeautifulSoup\\\\nrocks!\\'</samp>\\n</pre></div>\\n\\n<p>Here\\'s a more complex example that uses <code>recursiveChildGenerator</code>\\nto iterate over the elements of a document, printing each one as it\\ngets it.\\n\\n<div class=\"sample\"><pre>\\n<kbd>from BeautifulSoup import BeautifulSoup</kbd>\\n<kbd>soup = BeautifulSoup(\"1&lt;a&gt;2&lt;b&gt;3\")</kbd>\\n<kbd>g = soup.recursiveChildGenerator()</kbd>\\n<kbd>while True:</kbd>\\n<kbd>    try:</kbd>\\n<kbd>        print g.next()</kbd>\\n<kbd>    except StopIteration:</kbd>\\n<kbd>        break</kbd>\\n# <samp>1</samp>\\n# <samp>&lt;a&gt;2&lt;b&gt;3&lt;/b&gt;&lt;/a&gt;</samp>\\n# <samp>2</samp>\\n# <samp>&lt;b&gt;3&lt;/b&gt;</samp>\\n# <samp>3</samp>\\n</pre></div>\\n\\n<a name=\"Other Built-In Parsers\"><h3>Other Built-In Parsers</h3></a>\\n\\n<p>Beautiful Soup comes with three parser classes besides <a\\nhref=\"#Parsing HTML\"><code>BeautifulSoup</code></a> and <a href=\"#Parsing XML\">\\n<code>BeautifulStoneSoup</code></a>:\\n\\n<ul>\\n\\n<li><p><code>MinimalSoup</code> is a subclass of <code>BeautifulSoup</code>. It knows most\\nfacts about HTML like which tags are self-closing, the special\\nbehavior of the &lt;SCRIPT&gt; tag, the possibility of an encoding mentioned\\nin a &lt;META&gt; tag, etc. But it has no nesting heuristics at all. So it\\ndoesn\\'t know that &lt;LI&gt; tags go underneath &lt;UL&gt; tags and not the other\\nway around. It\\'s useful for parsing pathologically bad markup, and for\\nsubclassing.\\n\\n<li><p><code>ICantBelieveItsBeautifulSoup</code> is also a subclass of\\n<code>BeautifulSoup</code>. It has HTML heuristics that conform more\\nclosely to the HTML standard, but ignore how HTML is used in the real\\nworld. For instance, it\\'s valid HTML to nest &lt;B&gt; tags, but in the real\\nworld a nested &lt;B&gt; tag almost always means that the author forgot to\\nclose the first &lt;B&gt; tag. If you run into someone who actually nests\\n&lt;B&gt; tags, then you can use <code>ICantBelieveItsBeautifulSoup</code>.\\n\\n<li><p><code>BeautifulSOAP</code> is a subclass of\\n<code>BeautifulStoneSoup</code>. It\\'s useful for parsing documents\\nlike SOAP messages, which use a subelement when they could just use an\\nattribute of the parent element. Here\\'s an example:\\n\\n<div class=\"sample\"><pre>\\n<kbd>from BeautifulSoup import BeautifulStoneSoup, BeautifulSOAP</kbd>\\n<kbd>xml = \"&lt;doc&gt;&lt;tag&gt;subelement&lt;/tag&gt;&lt;/doc&gt;\"</kbd>\\n<kbd>print BeautifulStoneSoup(xml)</kbd>\\n# <samp>&lt;doc&gt;&lt;tag&gt;subelement&lt;/tag&gt;&lt;/doc&gt;</samp>\\n<kbd>print BeautifulSOAP(xml)</kbd>\\n<kbd>&lt;doc tag=\"subelement\"&gt;&lt;tag&gt;subelement&lt;/tag&gt;&lt;/doc&gt;</kbd>\\n</pre></div>\\n\\n<p>With <code>BeautifulSOAP</code> you can access the contents of the\\n&lt;TAG&gt; tag without descending into the tag.\\n\\n</ul>\\n\\n<a name=\"Customizing the Parser\"><h3>Customizing the Parser</h3></a>\\n\\n<p>When the built-in parser classes won\\'t do the job, you need to\\ncustomize. This usually means customizing the lists of nestable and\\nself-closing tags. You can customize the list of self-closing tags by\\npassing a <a href=\"#selfClosingTags\"><code>selfClosingTags</code></a> argument\\ninto the soup constructor. To customize the lists of nestable tags,\\nthough, you\\'ll have to subclass.\\n\\n<p>The most useful classes to subclass are <code>MinimalSoup</code> (for HTML)\\nand <code>BeautifulStoneSoup</code> (for XML). I\\'m going to show you how to\\noverride <code>RESET_NESTING_TAGS</code> and <code>NESTABLE_TAGS</code> in a subclass. This\\nis the most complicated part of Beautiful Soup and I\\'m not going to\\nexplain it very well here, but I\\'ll get something written and then I\\ncan improve it with feedback.\\n\\n<p>When Beautiful Soup is parsing a document, it keeps a stack of open\\ntags. Whenever it sees a new start tag, it tosses that tag on top of\\nthe stack. But before it does, it might close some of the open tags\\nand remove them from the stack. Which tags it closes depends on the\\nqualities of tag it just found, and the qualities of the tags in the\\nstack.\\n\\n<p>The best way to explain it is through example. Let\\'s say the stack\\nlooks like <code>[\\'html\\', \\'p\\', \\'b\\']</code>, and Beautiful Soup encounters a &lt;P&gt;\\ntag. If it just tossed another <code>\\'p\\'</code> onto the stack, this would imply\\nthat the second &lt;P&gt; tag is within the first &lt;P&gt; tag, not to mention\\nthe open &lt;B&gt; tag. But that\\'s not the way &lt;P&gt; tags work. You can\\'t\\nstick a &lt;P&gt; tag inside another &lt;P&gt; tag. A &lt;P&gt; tag isn\\'t \"nestable\" at\\nall.\\n\\n<p>So when Beautiful Soup encounters a &lt;P&gt; tag, it closes and pops all\\nthe tags up to and including the previously encountered tag of the\\nsame type. This is the default behavior, and this is how\\n<code>BeautifulStoneSoup</code> treats <i>every</i> tag. It\\'s what you get when a\\ntag is not mentioned in either <code>NESTABLE_TAGS</code> or\\n<code>RESET_NESTING_TAGS</code>. It\\'s also what you get when a tag shows up in\\n<code>RESET_NESTING_TAGS</code> but has no entry in <code>NESTABLE_TAGS</code>, the way the\\n&lt;P&gt; tag does.\\n\\n<div class=\"sample\"><pre>\\n<kbd>from BeautifulSoup import BeautifulSoup</kbd>\\n<kbd>BeautifulSoup.RESET_NESTING_TAGS[\\'p\\'] == None</kbd>\\n# <samp>True</samp>\\n<kbd>BeautifulSoup.NESTABLE_TAGS.has_key(\\'p\\')</kbd>\\n# <samp>False</samp>\\n<kbd></kbd>\\n<kbd>print BeautifulSoup(\"&lt;html&gt;&lt;p&gt;Para&lt;b&gt;one&lt;p&gt;Para two\")</kbd>\\n# <samp>&lt;html&gt;&lt;p&gt;Para&lt;b&gt;one&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Para two&lt;/p&gt;&lt;/html&gt;</samp>\\n# <samp>                     ^---^--The second &lt;p&gt; tag made those two tags get closed</samp>\\n</pre></div>\\n\\n<p>Let\\'s say the stack looks like <code>[\\'html\\', \\'span\\', \\'b\\']</code>, and\\nBeautiful Soup encounters a &lt;SPAN&gt; tag. Now, &lt;SPAN&gt; tags can contain\\nother &lt;SPAN&gt; tags without limit, so there\\'s no need to pop up to the\\nprevious &lt;SPAN&gt; tag when you encounter one. This is represented by\\nmapping the tag name to an empty list in <code>NESTABLE_TAGS</code>. This kind of\\ntag should not be mentioned in <code>RESET_NESTING_TAGS</code>: there are no\\ncircumstances when encountering a &lt;SPAN&gt; tag would cause any tags to\\nbe popped.\\n\\n<div class=\"sample\"><pre>\\n<kbd>from BeautifulSoup import BeautifulSoup</kbd>\\n<kbd>BeautifulSoup.NESTABLE_TAGS[\\'span\\']</kbd>\\n# <samp>[]</samp>\\n<kbd>BeautifulSoup.RESET_NESTING_TAGS.has_key(\\'span\\')</kbd>\\n# <samp>False</samp>\\n<kbd></kbd>\\n<kbd>print BeautifulSoup(\"&lt;html&gt;&lt;span&gt;Span&lt;b&gt;one&lt;span&gt;Span two\")</kbd>\\n# <samp>&lt;html&gt;&lt;span&gt;Span&lt;b&gt;one&lt;span&gt;Span two&lt;/span&gt;&lt;/b&gt;&lt;/span&gt;&lt;/html&gt;</samp>\\n</pre></div>\\n\\n<p>Third example: suppose the stack looks like <code>[\\'ol\\',\\'li\\',\\'ul\\']</code>:\\nthat is, we\\'ve got an ordered list, the first element of which\\ncontains an unordered list. Now suppose Beautiful Soup encounters a\\n&lt;LI&gt; tag. It shouldn\\'t pop up to the first &lt;LI&gt; tag, because this new\\n&lt;LI&gt; tag is part of the unordered sublist. It\\'s okay for an &lt;LI&gt; tag\\nto be inside another &lt;LI&gt; tag, so long as there\\'s a &lt;UL&gt; or &lt;OL&gt; tag\\nin the way.\\n\\n<div class=\"sample\"><pre>\\n<kbd>from BeautifulSoup import BeautifulSoup</kbd>\\n<kbd>print BeautifulSoup(\"&lt;ol&gt;&lt;li&gt;1&lt;ul&gt;&lt;li&gt;A\").prettify()</kbd>\\n# <samp>&lt;ol&gt;</samp>\\n# <samp> &lt;li&gt;</samp>\\n# <samp>  1</samp>\\n# <samp>  &lt;ul&gt;</samp>\\n# <samp>   &lt;li&gt;</samp>\\n# <samp>    A</samp>\\n# <samp>   &lt;/li&gt;</samp>\\n# <samp>  &lt;/ul&gt;</samp>\\n# <samp> &lt;/li&gt;</samp>\\n# <samp>&lt;/ol&gt;</samp>\\n</pre></div>\\n\\n<p>But if there is no intervening &lt;UL&gt; or &lt;OL&gt;, then one &lt;LI&gt; tag\\ncan\\'t be underneath another:\\n\\n<div class=\"sample\"><pre>\\n<kbd>print BeautifulSoup(\"&lt;ol&gt;&lt;li&gt;1&lt;li&gt;A\").prettify()</kbd>\\n# <samp>&lt;ol&gt;</samp>\\n# <samp> &lt;li&gt;</samp>\\n# <samp>  1</samp>\\n# <samp> &lt;/li&gt;</samp>\\n# <samp> &lt;li&gt;</samp>\\n# <samp>  A</samp>\\n# <samp> &lt;/li&gt;</samp>\\n# <samp>&lt;/ol&gt;</samp>\\n</pre></div>\\n\\n<p>We tell Beautiful Soup to treat &lt;LI&gt; tags this way by putting \"li\"\\nin <code>RESET_NESTING_TAGS</code>, and by giving \"li\" a <code>NESTABLE_TAGS</code> entry\\nshowing list of tags under which it can nest.\\n\\n<div class=\"sample\"><pre>\\n<kbd>BeautifulSoup.RESET_NESTING_TAGS.has_key(\\'li\\')</kbd>\\n# <samp>True</samp>\\n<kbd>BeautifulSoup.NESTABLE_TAGS[\\'li\\']</kbd>\\n# <samp>[\\'ul\\', \\'ol\\']</samp>\\n</pre></div>\\n\\n<p>This is also how we handle the nesting of table tags:\\n\\n<div class=\"sample\"><pre>\\n<kbd>BeautifulSoup.NESTABLE_TAGS[\\'td\\']</kbd>\\n# <samp>[\\'tr\\']</samp>\\n<kbd>BeautifulSoup.NESTABLE_TAGS[\\'tr\\']</kbd>\\n# <samp>[\\'table\\', \\'tbody\\', \\'tfoot\\', \\'thead\\']</samp>\\n<kbd>BeautifulSoup.NESTABLE_TAGS[\\'tbody\\']</kbd>\\n# <samp>[\\'table\\']</samp>\\n<kbd>BeautifulSoup.NESTABLE_TAGS[\\'thead\\']</kbd>\\n# <samp>[\\'table\\']</samp>\\n<kbd>BeautifulSoup.NESTABLE_TAGS[\\'tfoot\\']</kbd>\\n# <samp>[\\'table\\']</samp>\\n<kbd>BeautifulSoup.NESTABLE_TAGS[\\'table\\']</kbd>\\n# <samp>[]</samp>\\n</pre></div>\\n\\n<p>That is: &lt;TD&gt; tags can be nested within &lt;TR&gt; tags. &lt;TR&gt; tags can be\\nnested within &lt;TABLE&gt;, &lt;TBODY&gt;, &lt;TFOOT&gt;, and &lt;THEAD&gt; tags. &lt;TBODY&gt;,\\n&lt;TFOOT&gt;, and &lt;THEAD&gt; tags can be nested in &lt;TABLE&gt; tags, and &lt;TABLE&gt;\\ntags can be nested in other &lt;TABLE&gt; tags. If you know about HTML\\ntables, these rules should already make sense to you.\\n\\n<p>One more example. Say the stack looks like <code>[\\'html\\', \\'p\\', \\'table\\']</code>\\nand Beautiful Soup encounters a &lt;P&gt; tag. \\n\\n<p>At first glance, this looks just like the example where the stack\\nis <code>[\\'html\\', \\'p\\', \\'b\\']</code> and Beautiful Soup encounters a &lt;P&gt; tag. In\\nthat example, we closed the &lt;B&gt; and &lt;P&gt; tags, because you can\\'t have\\none paragraph inside another.\\n\\n<p>Except... you <i>can</i> have a paragraph that contains a table,\\nand then the table contains a paragraph. So the right thing to do is\\nto not close any of these tags. Beautiful Soup does the right thing:\\n\\n<div class=\"sample\"><pre>\\n<kbd>from BeautifulSoup import BeautifulSoup</kbd>\\n<kbd>print BeautifulSoup(\"&lt;p&gt;Para 1&lt;b&gt;&lt;p&gt;Para 2\")</kbd>\\n# <samp>&lt;p&gt;</samp>\\n# <samp> Para 1</samp>\\n# <samp> &lt;b&gt;</samp>\\n# <samp> &lt;/b&gt;</samp>\\n# <samp>&lt;/p&gt;</samp>\\n# <samp>&lt;p&gt;</samp>\\n# <samp> Para 2</samp>\\n# <samp>&lt;/p&gt;</samp>\\n<kbd></kbd>\\n<kbd>print BeautifulSoup(\"&lt;p&gt;Para 1&lt;table&gt;&lt;p&gt;Para 2\").prettify()</kbd>\\n# <samp>&lt;p&gt;</samp>\\n# <samp> Para 1</samp>\\n# <samp> &lt;table&gt;</samp>\\n# <samp>  &lt;p&gt;</samp>\\n# <samp>   Para 2</samp>\\n# <samp>  &lt;/p&gt;</samp>\\n# <samp> &lt;/table&gt;</samp>\\n# <samp>&lt;/p&gt;</samp>\\n</pre></div>\\n\\n<p>What\\'s the difference? The difference is that &lt;TABLE&gt; is in\\n<code>RESET_NESTING_TAGS</code> and &lt;B&gt; is not. A tag that\\'s in\\n<code>RESET_NESTING_TAGS</code> doesn\\'t get popped off the stack as easily as a\\ntag that\\'s not. \\n\\n<p>Okay, hopefully you get the idea. Here\\'s the <code>NESTABLE_TAGS</code> for\\nthe <code>BeautifulSoup</code> class. Correlate this with what you know about\\nHTML, and you should be able to create your own <code>NESTABLE_TAGS</code> for\\nbizarre HTML documents that don\\'t follow the normal rules, and for\\nother XML dialects that have different nesting rules.\\n\\n<div class=\"sample\"><pre>\\n<kbd>from BeautifulSoup import BeautifulSoup</kbd>\\n<kbd>nestKeys = BeautifulSoup.NESTABLE_TAGS.keys()</kbd>\\n<kbd>nestKeys.sort()</kbd>\\n<kbd>for key in nestKeys:</kbd>\\n<kbd>    print \"%s: %s\" % (key, BeautifulSoup.NESTABLE_TAGS[key])</kbd>\\n# <samp>bdo: []</samp>\\n# <samp>blockquote: []</samp>\\n# <samp>center: []</samp>\\n# <samp>dd: [\\'dl\\']</samp>\\n# <samp>del: []</samp>\\n# <samp>div: []</samp>\\n# <samp>dl: []</samp>\\n# <samp>dt: [\\'dl\\']</samp>\\n# <samp>fieldset: []</samp>\\n# <samp>font: []</samp>\\n# <samp>ins: []</samp>\\n# <samp>li: [\\'ul\\', \\'ol\\']</samp>\\n# <samp>object: []</samp>\\n# <samp>ol: []</samp>\\n# <samp>q: []</samp>\\n# <samp>span: []</samp>\\n# <samp>sub: []</samp>\\n# <samp>sup: []</samp>\\n# <samp>table: []</samp>\\n# <samp>tbody: [\\'table\\']</samp>\\n# <samp>td: [\\'tr\\']</samp>\\n# <samp>tfoot: [\\'table\\']</samp>\\n# <samp>th: [\\'tr\\']</samp>\\n# <samp>thead: [\\'table\\']</samp>\\n# <samp>tr: [\\'table\\', \\'tbody\\', \\'tfoot\\', \\'thead\\']</samp>\\n# <samp>ul: []</samp>\\n</pre></div>\\n\\n<p>And here\\'s <code>BeautifulSoup</code>\\'s <code>RESET_NESTING_TAGS</code>. Only the keys\\nare important: <code>RESET_NESTING_TAGS</code> is actually a list, put into the\\nform of a dictionary for quick random access.\\n\\n<div class=\"sample\"><pre>\\n<kbd>from BeautifulSoup import BeautifulSoup</kbd>\\n<kbd>resetKeys = BeautifulSoup.RESET_NESTING_TAGS.keys()</kbd>\\n<kbd>resetKeys.sort()</kbd>\\n<kbd>resetKeys</kbd>\\n# <samp>[\\'address\\', \\'blockquote\\', \\'dd\\', \\'del\\', \\'div\\', \\'dl\\', \\'dt\\', \\'fieldset\\', </samp>\\n# <samp> \\'form\\', \\'ins\\', \\'li\\', \\'noscript\\', \\'ol\\', \\'p\\', \\'pre\\', \\'table\\', \\'tbody\\',</samp>\\n# <samp> \\'td\\', \\'tfoot\\', \\'th\\', \\'thead\\', \\'tr\\', \\'ul\\']</samp>\\n</pre></div>\\n\\n<p>Since you\\'re subclassing anyway, you might as well override\\n<code>SELF_CLOSING_TAGS</code> while you\\'re at it. It\\'s a dictionary that maps\\nself-closing tag names to any values at all (like\\n<code>RESET_NESTING_TAGS</code>, it\\'s actually a list in the form of a\\ndictionary). Then you won\\'t have to pass that list in to the\\nconstructor (as <code>selfClosingTags</code>) every time you instantiate your\\nsubclass.\\n\\n<a name=\"Entity Conversion\"><h3>Entity Conversion</h3></a>\\n\\n<p>When you parse a document, you can convert HTML or XML entity\\nreferences to the corresponding Unicode characters. This code converts\\nthe HTML entity \"&amp;eacute;\" to the Unicode character LATIN SMALL\\nLETTER E WITH ACUTE, and the numeric entity \"&amp;#101;\" to the Unicode\\ncharacter LATIN SMALL LETTER E.\\n\\n<div class=\"sample\"><pre>\\n<kbd>from BeautifulSoup import BeautifulStoneSoup</kbd>\\n<kbd>BeautifulStoneSoup(\"Sacr&amp;eacute; bl&amp;#101;u!\", </kbd>\\n<kbd>                   convertEntities=BeautifulStoneSoup.HTML_ENTITIES).contents[0]</kbd>\\n# <samp>u\\'Sacr\\\\xe9 bleu!\\'</samp>\\n</pre></div>\\n\\n<p>That\\'s if you use <code>HTML_ENTITIES</code> (which is just the string\\n\"html\"). If you use <code>XML_ENTITIES</code> (or the string \"xml\"), then only\\nnumeric entities and the five XML entities (\"&amp;quot;\",\\n\"&amp;apos;\", \"&amp;gt;\", \"&amp;lt;\", and \"&amp;amp;\") get\\nconverted. If you use <code>ALL_ENTITIES</code> (or the list <code>[\"xml\", \"html\"]</code>),\\nthen both kinds of entities will be converted. This last one is\\nneccessary because &amp;apos; is an XML entity but not an HTML\\nentity.\\n\\n<div class=\"sample\"><pre>\\n<kbd>BeautifulStoneSoup(\"Sacr&amp;eacute; bl&amp;#101;u!\", </kbd>\\n<kbd>                   convertEntities=BeautifulStoneSoup.XML_ENTITIES)</kbd>\\n# <samp>Sacr&amp;eacute; bleu!</samp>\\n<kbd></kbd>\\n<kbd>from BeautifulSoup import BeautifulStoneSoup</kbd>\\n<kbd>BeautifulStoneSoup(\"Il a dit, &amp;lt;&amp;lt;Sacr&amp;eacute; bl&amp;#101;u!&amp;gt;&amp;gt;\", </kbd>\\n<kbd>                   convertEntities=BeautifulStoneSoup.XML_ENTITIES)</kbd>\\n# <samp>Il a dit, &lt;&lt;Sacr&amp;eacute; bleu!&gt;&gt;</samp>\\n</pre></div>\\n\\n<p>If you tell Beautiful Soup to convert XML or HTML entities into the\\ncorresponding Unicode characters, then Windows-1252 characters (like\\nMicrosoft smart quotes) also get transformed into Unicode\\ncharacters. This happens even if you told Beautiful Soup to convert\\nthose characters to entities.\\n\\n<div class=\"sample\"><pre>\\n<kbd>from BeautifulSoup import BeautifulStoneSoup</kbd>\\n<kbd>smartQuotesAndEntities = \"Il a dit, \\\\x8BSacr&amp;eacute; bl&amp;#101;u!\\\\x9b\"</kbd>\\n<kbd></kbd>\\n<kbd>BeautifulStoneSoup(smartQuotesAndEntities, smartQuotesTo=\"html\").contents[0]</kbd>\\n# <samp>u\\'Il a dit, &amp;lsaquo;Sacr&amp;eacute; bl&amp;#101;u!&amp;rsaquo;\\'</samp>\\n<kbd></kbd>\\n<kbd>BeautifulStoneSoup(smartQuotesAndEntities, convertEntities=\"html\", </kbd>\\n<kbd>                   smartQuotesTo=\"html\").contents[0]</kbd>\\n# <samp>u\\'Il a dit, \\\\u2039Sacr\\\\xe9 bleu!\\\\u203a\\'</samp>\\n<kbd></kbd>\\n<kbd>BeautifulStoneSoup(smartQuotesAndEntities, convertEntities=\"xml\", </kbd>\\n<kbd>                   smartQuotesTo=\"xml\").contents[0]</kbd>\\n# <samp>u\\'Il a dit, \\\\u2039Sacr&amp;eacute; bleu!\\\\u203a\\'</samp>\\n</pre></div>\\n\\n<p>It doesn\\'t make sense to create new HTML/XML entities while you\\'re\\nbusy turning all the existing entities into Unicode\\ncharacters.\\n\\n<a name=\"Sanitizing Bad Data with Regexps\"><h3>Sanitizing Bad Data with Regexps</h3></a>\\n\\n<p>Beautiful Soup does pretty well at handling bad markup when \"bad\\nmarkup\" means tags in the wrong places. But sometimes the markup is\\njust malformed, and the underlying parser can\\'t handle it. So\\nBeautiful Soup runs regular expressions against an input document\\nbefore trying to parse it.\\n\\n<p>By default, Beautiful Soup uses regular expressions and replacement\\nfunctions to do search-and-replace on input documents. It finds\\nself-closing tags that look like &lt;BR/&gt;, and changes them to look like\\n&lt;BR /&gt;. It finds declarations that have extraneous whitespace, like \\n&lt;! --Comment--&gt;, and removes the whitespace: &lt;!--Comment--&gt;.\\n\\n<p>If you have bad markup that needs fixing in some other way, you can\\npass your own list of <code>(regular expression, replacement function)</code>\\ntuples into the soup constructor, as the <code>markupMassage</code> argument.\\n\\n<p>Let\\'s take an example: a page that has a malformed comment. The\\nunderlying SGML parser can\\'t cope with this, and ignores the comment\\nand everything afterwards:\\n\\n<div class=\"sample\"><pre>\\n<kbd>from BeautifulSoup import BeautifulSoup</kbd>\\n<kbd>badString = \"Foo&lt;!-This comment is malformed.--&gt;Bar&lt;br/&gt;Baz\"</kbd>\\n<kbd>BeautifulSoup(badString)</kbd>\\n# <samp>Foo</samp>\\n</pre></div>\\n\\n<p>Let\\'s fix it up with a regular expression and a function:\\n\\n<div class=\"sample\"><pre>\\n<kbd>import re</kbd>\\n<kbd>myMassage = [(re.compile(\\'&lt;!-([^-])\\'), lambda match: \\'&lt;!--\\' + match.group(1))]</kbd>\\n<kbd>BeautifulSoup(badString, markupMassage=myMassage)</kbd>\\n# <samp>Foo&lt;!--This comment is malformed.--&gt;Bar</samp>\\n</pre></div>\\n\\n<p>Oops, we\\'re still missing the &lt;BR&gt; tag. Our <code>markupMassage</code>\\noverrides the parser\\'s default massage, so the default\\nsearch-and-replace functions don\\'t get run. The parser makes it past\\nthe comment, but it dies at the malformed self-closing tag. Let\\'s add\\nour new massage function to the default list, so we run all the\\nfunctions.\\n\\n<div class=\"sample\"><pre>\\n<kbd>import copy</kbd>\\n<kbd>myNewMassage = copy.copy(BeautifulSoup.MARKUP_MASSAGE)</kbd>\\n<kbd>myNewMassage.extend(myMassage)</kbd>\\n<kbd>BeautifulSoup(badString, markupMassage=myNewMassage)</kbd>\\n# <samp>Foo&lt;!--This comment is malformed.--&gt;Bar&lt;br /&gt;Baz</samp>\\n</pre></div>\\n\\n<p>Now we\\'ve got it all.\\n\\n<p>If you know for a fact that your markup doesn\\'t need any regular\\nexpressions run on it, you can get a faster startup time by passing in\\n<code>False</code> for <code>markupMassage</code>.\\n\\n<a name=\"Fun With SoupStrainers\"><h3>Fun With <code>SoupStrainer</code>s</h3></a>\\n\\n<p>Recall that all the search methods take more or less <a\\nhref=\"#args\">the same arguments</a>. Behind the scenes, your arguments\\nto a search method get transformed into a <code>SoupStrainer</code> object. If\\nyou call one of the methods that returns a list (like <code>findAll</code>), the\\n<code>SoupStrainer</code> object is made available as the <code>source</code> property of\\nthe resulting list.\\n\\n<div class=\"sample\"><pre>\\n<kbd>from BeautifulSoup import BeautifulStoneSoup</kbd>\\n<kbd>xml = \\'&lt;person name=\"Bob\"&gt;&lt;parent rel=\"mother\" name=\"Alice\"&gt;\\'</kbd>\\n<kbd>xmlSoup = BeautifulStoneSoup(xml)</kbd>\\n<kbd>results = xmlSoup.findAll(rel=\\'mother\\')</kbd>\\n<kbd></kbd>\\n<kbd>results.source</kbd>\\n# <samp>&lt;BeautifulSoup.SoupStrainer instance at 0xb7e0158c&gt;</samp>\\n<kbd>str(results.source)</kbd>\\n# <samp>\"None|{\\'rel\\': \\'mother\\'}\"</samp>\\n</pre></div>\\n\\n<p>The <code>SoupStrainer</code> constructor takes most of the same arguments as\\n<code>find</code>: <code><a href=\"#arg-name\">name</a></code>, <code><a href=\"#arg-attrs\">attrs</a></code>, <code><a href=\"#arg-text\">text</a></code>, and <code><a href=\"#arg-**kwargs\">**kwargs</a></code>. You can pass\\nin a <code>SoupStrainer</code> as the <code>name</code> argument to any search method:\\n\\n<div class=\"sample\"><pre>\\n<kbd>xmlSoup.findAll(results.source) == results</kbd>\\n# <samp>True</samp>\\n<kbd></kbd>\\n<kbd>customStrainer = BeautifulSoup.SoupStrainer(rel=\\'mother\\')</kbd>\\n<kbd>xmlSoup.findAll(customStrainer) == results</kbd>\\n# <samp> True</samp>\\n</pre></div>\\n\\n<p>Yeah, who cares, right? You can carry around a method call\\'s\\narguments in many other ways. But another thing you can do with\\n<code>SoupStrainer</code> is pass it into the soup constructor to restrict the\\nparts of the document that actually get parsed. That brings us to the\\nnext section:\\n\\n<a name=\"Improving Performance by Parsing Only Part of the Document\"><h3>Improving Performance by Parsing Only Part of the Document</h3></a>\\n\\n<p>Beautiful Soup turns every element of a document into a Python\\nobject and connects it to a bunch of other Python objects. If you only\\nneed a subset of the document, this is really slow. But you can pass\\nin a <a href=\"#Fun With SoupStrainers\"><code>SoupStrainer</code></a> as the\\n<code>parseOnlyThese</code> argument to the soup constructor. Beautiful Soup\\nchecks each element against the <code>SoupStrainer</code>, and only if it matches\\nis the element turned into a <code>Tag</code> or <code>NavigableText</code>, and added to\\nthe tree.\\n\\n<p>If an element is added to to the tree, then so are its\\nchildren&mdash;even if they wouldn\\'t have matched the <code>SoupStrainer</code>\\non their own. This lets you parse only the chunks of a document that\\ncontain the data you want.\\n\\n<p>Here\\'s a pretty varied document:\\n\\n<div class=\"sample\"><pre>\\n<kbd>doc = \\'\\'\\'Bob reports &lt;a href=\"http://www.bob.com/\"&gt;success&lt;/a&gt;</kbd>\\n<kbd>with his plasma breeding &lt;a</kbd>\\n<kbd>href=\"http://www.bob.com/plasma\"&gt;experiments&lt;/a&gt;. &lt;i&gt;Don\\'t get any on</kbd>\\n<kbd>us, Bob!&lt;/i&gt;</kbd>\\n<kbd></kbd>\\n<kbd>&lt;br&gt;&lt;br&gt;Ever hear of annular fusion? The folks at &lt;a</kbd>\\n<kbd>href=\"http://www.boogabooga.net/\"&gt;BoogaBooga&lt;/a&gt; sure seem obsessed</kbd>\\n<kbd>with it. Secret project, or &lt;b&gt;WEB MADNESS?&lt;/b&gt; You decide!\\'\\'\\'</kbd>\\n</pre></div>\\n\\n<p>Here are several different ways of parsing the document into soup,\\ndepending on which parts you want. All of these are faster and use\\nless memory than parsing the whole document and then using the same\\n<code>SoupStrainer</code> to pick out the parts you want.\\n\\n<div class=\"sample\"><pre>\\n<kbd>from BeautifulSoup import BeautifulSoup, SoupStrainer</kbd>\\n<kbd>import re</kbd>\\n<kbd></kbd>\\n<kbd>links = SoupStrainer(\\'a\\')</kbd>\\n<kbd>[tag for tag in BeautifulSoup(doc, parseOnlyThese=links)]</kbd>\\n# <samp>[&lt;a href=\"http://www.bob.com/\"&gt;success&lt;/a&gt;, </samp>\\n# <samp> &lt;a href=\"http://www.bob.com/plasma\"&gt;experiments&lt;/a&gt;, </samp>\\n# <samp> &lt;a href=\"http://www.boogabooga.net/\"&gt;BoogaBooga&lt;/a&gt;]</samp>\\n<kbd></kbd>\\n<kbd>linksToBob = SoupStrainer(\\'a\\', href=re.compile(\\'bob.com/\\'))</kbd>\\n<kbd>[tag for tag in BeautifulSoup(doc, parseOnlyThese=linksToBob)]</kbd>\\n# <samp>[&lt;a href=\"http://www.bob.com/\"&gt;success&lt;/a&gt;, </samp>\\n# <samp> &lt;a href=\"http://www.bob.com/plasma\"&gt;experiments&lt;/a&gt;]</samp>\\n<kbd></kbd>\\n<kbd>mentionsOfBob = SoupStrainer(text=re.compile(\"Bob\"))</kbd>\\n<kbd>[text for text in BeautifulSoup(doc, parseOnlyThese=mentionsOfBob)]</kbd>\\n# <samp>[u\\'Bob reports \\', u\"Don\\'t get any on\\\\nus, Bob!\"]</samp>\\n<kbd></kbd>\\n<kbd>allCaps = SoupStrainer(text=lambda(t):t.upper()==t)</kbd>\\n<kbd>[text for text in BeautifulSoup(doc, parseOnlyThese=allCaps)]</kbd>\\n# <samp>[u\\'. \\', u\\'\\\\n\\', u\\'WEB MADNESS?\\']</samp>\\n</pre></div>\\n\\n<p>There is one major difference between the <code>SoupStrainer</code> you pass\\ninto a search method and the one you pass into a soup\\nconstructor. Recall that the <code>name</code> argument can take <a\\nhref=\"#match-callable\">a function whose argument is a <code>Tag</code>\\nobject</a>. You can\\'t do this for a <code>SoupStrainer</code>\\'s <code>name</code>, because\\nthe <code>SoupStrainer</code> is used to decide whether or not a <code>Tag</code> object\\nshould be created in the first place. You can pass in a function for a\\n<code>SoupStrainer</code>\\'s <code>name</code>, but it can\\'t take a <code>Tag</code> object: it can only\\ntake the tag name and a map of arguments.\\n\\n<div class=\"sample\"><pre>\\n<kbd>shortWithNoAttrs = SoupStrainer(lambda name, attrs: \\\\</kbd>\\n<kbd>                                len(name) == 1 and not attrs)</kbd>\\n<kbd>[tag for tag in BeautifulSoup(doc, parseOnlyThese=shortWithNoAttrs)]</kbd>\\n# <samp>[&lt;i&gt;Don\\'t get any on us, Bob!&lt;/i&gt;, </samp>\\n# <samp> &lt;b&gt;WEB MADNESS?&lt;/b&gt;]</samp>\\n</pre></div>\\n\\n<a name=\"Improving Memory Usage with extract\"><h3>Improving Memory Usage with <code>extract</code></h3></a>\\n\\n<p>When Beautiful Soup parses a document, it loads into memory a large,\\ndensely connected data structure. If you just need a string from that\\ndata structure, you might think that you can grab the string and leave\\nthe rest of it to be garbage collected. Not so. That string is a\\n<code>NavigableString</code> object. It\\'s got a <code>parent</code> member that points to a\\n<code>Tag</code> object, which points to other <code>Tag</code> objects, and so on. So long\\nas you hold on to any part of the tree, you\\'re keeping the whole thing\\nin memory.\\n\\n<p>The <code>extract</code> method breaks those connections. If you call\\n<code>extract</code> on the string you need, it gets disconnected from the rest\\nof the parse tree. The rest of the tree can then go out of scope and\\nbe garbage collected, while you use the string for something else. If\\nyou just need a small part of the tree, you can call <code>extract</code> on its\\ntop-level <code>Tag</code> and let the rest of the tree get garbage collected.\\n\\n<p>This works the other way, too. If there\\'s a big chunk of the\\ndocument you <i>don\\'t</i> need, you can call <code>extract</code> to rip it out\\nof the tree, then abandon it to be garbage collected while retaining\\ncontrol of the (smaller) tree. \\n\\n<p>If <code>extract</code> doesn\\'t work for you, you can try\\n<code>Tag.decompose</code>. It\\'s slower than <code>extract</code> but more thorough. It\\nrecursively disassembles a <code>Tag</code> and its contents, disconnecting every\\npart of a tree from every other part.\\n\\n<p>If you find yourself destroying big chunks of the tree, you might\\nhave been able to save time by \\n<a href=\"#Improving Performance by Parsing Only Part of the Document\">not\\nparsing that part of the tree in the first place</a>.\\n\\n<a name=\"See Also\"><h2>See Also</h2></a>\\n\\n<a name=\"Applications that use Beautiful Soup\"><h3>Applications that use Beautiful Soup</h3></a>\\n\\n<p>Lots of real-world applications use Beautiful Soup. Here are the\\npublicly visible applications that I know about:\\n\\n<ul>\\n\\n<li><a href=\"http://www.crummy.com/software/ScrapeNFeed\">Scrape \\'N\\'\\nFeed</a> is designed to work with Beautiful Soup to build RSS feeds\\nfor sites that don\\'t have them.\\n\\n<li><a href=\"http://www.meangrape.com/htmlatex/\">htmlatex</a> uses\\nBeautiful Soup to find LaTeX equations and render them as graphics.\\n\\n<li><a href=\"http://code.google.com/p/chmtopdf/\">chmtopdf</a> converts\\nCHM files to PDF format. Who am I to argue with that?\\n\\n<li>Duncan Gough\\'s <a\\nhref=\"http://www.suttree.com/code/fotopic/\">Fotopic backup</a> uses\\nBeautiful Soup to scrape the Fotopic website.\\n\\n<li>I&ntilde;igo Serna\\'s <a\\nhref=\"http://inigo.katxi.org/devel/misc/googlenews.py\">googlenews.py</a>\\nuses Beautiful Soup to scrape Google News (it\\'s in the parse_entry and\\nparse_category functions)\\n\\n<li>The <a href=\"http://potheads.ca/~cgm/weatheroffice/\">Weather\\nOffice Screen Scraper</a> uses Beautiful Soup to scrape the Canadian\\ngovernment\\'s weather office site.\\n\\n<li><a href=\"http://www.cs.duke.edu/~pbh/newsclues.html\">News\\nClues</a> uses Beautiful Soup to parse RSS feeds.\\n\\n<li><a href=\"http://blinkflash.sourceforge.net/\">BlinkFlash</a>\\nuses Beautiful Soup to automate form submission for an online service.\\n\\n<li>The <a\\nhref=\"http://www.voidspace.org.uk/python/programs.shtml#linky\">linky</a>\\nlink checker uses Beautiful Soup to find a page\\'s links and images\\nthat need checking.\\n\\n<li><A\\nhref=\"http://www.postneo.com/2005/03/28/mobile-screen-scraping-with-beautifulsoup-and-python-for-series-60\">Matt\\nCroydon</a> got Beautiful Soup 1.x to work on his Nokia Series 60\\nsmartphone. <a\\nhref=\"http://sandeep.weblogs.us/archives/024473.html\">C.R. Sandeep</a>\\nwrote a real-time currency converter for the Series 60 using Beautiful\\nSoup, but he won\\'t show us how he did it.\\n\\n<li>Here\\'s <a\\nhref=\"http://jacobian.org/recipes/archives/2005/03/21/fixing-tracks-bought-from-allofmp3com/\">a\\nshort script</a> from jacobian.org to fix the metadata on music files\\ndownloaded from allofmp3.com.\\n\\n<li>The <a href=\"http://www.pycs.net/\">Python Community Server</a>\\nuses Beautiful Soup in its spam detector.\\n\\n</ul>\\n\\n<a name=\"Similar libraries\"><h3>Similar libraries</h3></a>\\n\\n<p>I\\'ve found several other parsers for various languages that can\\nhandle bad markup, do tree traversal for you, or are otherwise more\\nuseful than your average parser.\\n\\n<ul>\\n\\n<li>I\\'ve ported Beautiful Soup to Ruby. The result is <a\\nhref=\"http://www.crummy.com/software/RubyfulSoup/\">Rubyful Soup</a>.\\n\\n<li><a href=\"http://code.whytheluckystiff.net/hpricot/\">Hpricot</a> is\\ngiving Rubyful Soup a run for its money.\\n\\n<li><a href=\"http://effbot.org/zone/element-index.htm\">ElementTree</a>\\nis a fast Python XML parser with a bad attitude. I love it.\\n\\n<li><a href=\"http://home.ccil.org/~cowan/XML/tagsoup/\">Tag Soup</a> is\\nan XML/HTML parser written in Java which rewrites bad HTML into\\nparseable HTML.\\n\\n<li><a href=\"http://www.neilvandyke.org/htmlprag/\">HtmlPrag</a> is a\\nScheme library for parsing bad HTML.\\n\\n<li><a href=\"http://www.aaronsw.com/2002/xmltramp/\">xmltramp</a> is a\\nnice take on a \\'standard\\' XML/XHTML parser. Like most parsers, it\\nmakes you traverse the tree yourself, but it\\'s easy to use.\\n\\n<li><a\\nhref=\"http://wwwsearch.sourceforge.net/pullparser/\">pullparser</a>\\nincludes a tree-traversal method.\\n\\n<li>Mike Foord didn\\'t like the way Beautiful Soup can change HTML if\\nyou write the tree back out, so he wrote <a\\nhref=\"http://aspn.activestate.com/ASPN/Cookbook/Python/Recipe/286269\">HTML\\nScraper</a>. It\\'s basically a version of HTMLParser that can handle\\nbad HTML. It might be obsolete with the release of Beautiful Soup 3.0,\\nthough; I\\'m not sure.\\n\\n<li>Ka-Ping Yee\\'s <a\\nhref=\"http://zesty.ca/python/scrape.py\">scrape.py</a> combines page\\nscraping with URL opening.\\n\\n</ul>\\n\\n<a name=\"Conclusion\"><h2>Conclusion</h2></a>\\n\\n<p>That\\'s it! Have fun! I wrote Beautiful Soup to save everybody\\ntime. Once you get used to it, you should be able to wrangle data out\\nof poorly-designed websites in just a few minutes. Send me email if\\nyou have any comments, run into problems, or want me to know about\\nyour project that uses Beautiful Soup.\\n\\n<p>--Leonard<hr><table><tr><td valign=\"top\">\\n<p>This document (<a href=\"/source/software/BeautifulSoup/bs3/documentation.bhtml\">source</a>) is part of Crummy, the webspace of <a href=\"/self/\">Leonard Richardson</a> (<a href=\"/self/contact.html\">contact information</a>). It was last modified on Saturday, December 07 2013, 20:02:22 Nowhere Standard Time and last built on Saturday, July 06 2019, 19:00:01 Nowhere Standard Time.</p><p><table class=\"licenseText\"><tr><td><a href=\"http://creativecommons.org/licenses/by-sa/2.0/\"><img border=\"0\" src=\"/nb//resources/img/somerights20.jpg\"></a></td><td valign=\"top\">Crummy is &copy; 1996-2019 Leonard Richardson. Unless otherwise noted, all text licensed under a <a href=\"http://creativecommons.org/licenses/by-sa/2.0/\">Creative Commons License</a>.</td></tr></table></span><!--<rdf:RDF xmlns=\"http://web.resource.org/cc/\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"><Work rdf:about=\"http://www.crummy.com/\"><dc:title>Crummy: The Site</dc:title><dc:rights><Agent><dc:title>Crummy: the Site</dc:title></Agent></dc:rights><dc:format>text/html</dc:format><license rdf:resource=http://creativecommons.org/licenses/by-sa/2.0//></Work><License rdf:about=\"http://creativecommons.org/licenses/by-sa/2.0/\"></License></rdf:RDF>--></p></td><td valign=top><p><b>Document tree:</b>\\n<dl><dd><a href=\"http://www.crummy.com/\">http://www.crummy.com/</a><dl><dd><a href=\"http://www.crummy.com/software/\">software/</a><dl><dd><a href=\"http://www.crummy.com/software/BeautifulSoup/\">BeautifulSoup/</a><dl><dd><a href=\"http://www.crummy.com/software/BeautifulSoup/bs3/\">bs3/</a><dl><dd><a href=\"http://www.crummy.com/software/BeautifulSoup/bs3/documentation.html\">documentation.html</a></dl>\\n</dl>\\n</dl>\\n</dl>\\n</dl>\\n\\n\\nSite Search:\\n\\n<form method=\"get\" action=\"/search/\">\\n        <input type=\"text\" name=\"q\" maxlength=\"255\" value=\"\"></input>\\n        </form>\\n        </td>\\n\\n</tr>\\n\\n</table>\\n</body>\\n</html>\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'bs4' has no attribute 'Beautifulsoup'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-182aae886709>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbs4\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBeautifulsoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'bs4' has no attribute 'Beautifulsoup'"
     ]
    }
   ],
   "source": [
    "soup = bs4.Beautifulsoup(res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
